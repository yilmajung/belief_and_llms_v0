{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yilmajung/belief_and_llms_v0/blob/main/1_extract_persona_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdMB_uZITACH",
        "outputId": "78ebda8c-d3b5-4587-f0f1-1c0f33a77cda"
      },
      "id": "qdMB_uZITACH",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6a7d1584",
      "metadata": {
        "id": "6a7d1584"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl2ZbmOFl_eB",
        "outputId": "309368b8-49ed-419b-ca3d-fac366729da3"
      },
      "id": "Bl2ZbmOFl_eB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "54bf7cce",
      "metadata": {
        "id": "54bf7cce"
      },
      "outputs": [],
      "source": [
        "# Load extraction_datasets.json\n",
        "import json\n",
        "with open(\"/content/drive/MyDrive/belief_and_llms_v0/gss_extraction_datasets.json\", \"r\") as f:\n",
        "    extraction_datasets = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "824b4112",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "824b4112",
        "outputId": "ed9d277b-e63c-4d11-c1bc-1fe2e0915a1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Race_person of different race than Black or White', 'Race_White person', 'Race_Black person', 'PartyID_Independent leaning Republican', 'PartyID_Strong Democrat', 'PartyID_Democrat', 'PartyID_Political Independent', 'PartyID_Strong Republican', 'PartyID_Independent leaning Democrat', 'PartyID_Other', 'PartyID_Republican', 'Sex_person', 'Degree_high school graduate', 'Degree_person with less than high school education', \"Degree_person with a bachelor's degree\", 'Degree_person with some college education', 'Degree_person with a graduate degree', 'Religion_Catholic', 'Religion_Protestant', 'Religion_person of other religion', 'Religion_Jewish', 'PolViews_person with a slightly liberal political view', 'PolViews_person with a conservative political view', 'PolViews_person with a liberal political view', 'PolViews_person with a neutral political view', 'PolViews_person with a slightly conservative political view', 'PolViews_person with an extremely liberal political view', 'PolViews_person with an extremely conservative political view', 'Generation_person from Generation X', 'Generation_person from the Silent Generation', 'Generation_Baby Boomer', 'Generation_Millennial', 'Generation_person from Generation Z'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "extraction_datasets.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f10a62f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1380a9a63002401bbbd75626406d9b4f",
            "f5e0f351609242eba95b0b266455a525",
            "79845bc10ff64373af8a6609bce21ba8",
            "62c5d7c54e244f4383a6c8503f1bedeb",
            "70cecb9a639d47c99ab63391ab8d7f0d",
            "afc9fb7b84b94a6cafeceae506f4dd28",
            "7665d9dca6514024bc3c031f95430598",
            "077fa8bace94494293f732ce1a3420f7",
            "b16a016f499e496f958895ab602b7a6b",
            "303c89512b0844b1aecd5b531c50f880",
            "1df64d6fff8f46bdb3c35733438b5cef"
          ]
        },
        "id": "f10a62f9",
        "outputId": "2f98850b-5edb-4aac-ffc5-5bd1805ad4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1380a9a63002401bbbd75626406d9b4f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Model Setup\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# Load model in 4-bit to save memory\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Choose the layer to hack\n",
        "TARGET_LAYER = 15\n",
        "SAVE_DIR = \"vectors\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Dictionary to store the final vectors in RAM\n",
        "# Structure: {'Race_Black person': Tensor(shape=[4096]), ...}\n",
        "demographic_vectors = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f4860d8b",
      "metadata": {
        "id": "f4860d8b"
      },
      "outputs": [],
      "source": [
        "# Helper: Hook Function\n",
        "\n",
        "def get_layer_activations(model, tokenizer, inputs_text, layer_idx):\n",
        "    \"\"\"\n",
        "    Paranoid version: explicitly checks tensor shape to avoid IndexError.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(inputs_text, return_tensors=\"pt\").to(model.device)\n",
        "    captured_hidden = None\n",
        "\n",
        "    def hook_fn(module, input, output):\n",
        "        nonlocal captured_hidden\n",
        "\n",
        "        # 1. UNWRAP TUPLE\n",
        "        # If the model returns (hidden_states, cache), take hidden_states.\n",
        "        if isinstance(output, tuple):\n",
        "            h_states = output[0]\n",
        "        else:\n",
        "            h_states = output\n",
        "\n",
        "        # 2. CHECK DIMENSIONS & SLICE\n",
        "        # h_states might be [Batch, Seq, Hidden] (3D) or [Seq, Hidden] (2D)\n",
        "\n",
        "        if h_states.dim() == 3:\n",
        "            # Case A: Standard [Batch, Seq, Hidden]\n",
        "            # We want Batch 0, Last Token (-1), All Features (:)\n",
        "            captured_hidden = h_states[0, -1, :].detach().cpu()\n",
        "\n",
        "        elif h_states.dim() == 2:\n",
        "            # Case B: [Seq, Hidden] (Batch dim missing)\n",
        "            # We want Last Token (-1), All Features (:)\n",
        "            captured_hidden = h_states[-1, :].detach().cpu()\n",
        "\n",
        "        else:\n",
        "            # Case C: Unexpected shape (just in case)\n",
        "            raise ValueError(f\"Unexpected tensor shape: {h_states.shape}\")\n",
        "\n",
        "    # Register and Run\n",
        "    layer = model.model.layers[layer_idx]\n",
        "    handle = layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model(**inputs)\n",
        "\n",
        "    handle.remove()\n",
        "    return captured_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e89ca900",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e89ca900",
        "outputId": "88be6a6f-d86f-4978-b415-9de53ea69204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting extraction on Layer 15...\n",
            "Processing: Race_person of different race than Black or White...\n",
            " -> Done. Magnitude: 2.2480\n",
            "Processing: Race_White person...\n",
            " -> Done. Magnitude: 1.7090\n",
            "Processing: Race_Black person...\n",
            " -> Done. Magnitude: 2.1680\n",
            "Processing: PartyID_Independent leaning Republican...\n",
            " -> Done. Magnitude: 2.3145\n",
            "Processing: PartyID_Strong Democrat...\n",
            " -> Done. Magnitude: 2.5156\n",
            "Processing: PartyID_Democrat...\n",
            " -> Done. Magnitude: 2.1836\n",
            "Processing: PartyID_Political Independent...\n",
            " -> Done. Magnitude: 2.3105\n",
            "Processing: PartyID_Strong Republican...\n",
            " -> Done. Magnitude: 2.7695\n",
            "Processing: PartyID_Independent leaning Democrat...\n",
            " -> Done. Magnitude: 2.1855\n",
            "Processing: PartyID_Other...\n",
            " -> Done. Magnitude: 0.9360\n",
            "Processing: PartyID_Republican...\n",
            " -> Done. Magnitude: 2.5371\n",
            "Processing: Sex_person...\n",
            " -> Done. Magnitude: 0.0000\n",
            "Processing: Degree_high school graduate...\n",
            " -> Done. Magnitude: 1.1113\n",
            "Processing: Degree_person with less than high school education...\n",
            " -> Done. Magnitude: 2.4180\n",
            "Processing: Degree_person with a bachelor's degree...\n",
            " -> Done. Magnitude: 0.8169\n",
            "Processing: Degree_person with some college education...\n",
            " -> Done. Magnitude: 0.8740\n",
            "Processing: Degree_person with a graduate degree...\n",
            " -> Done. Magnitude: 1.0801\n",
            "Processing: Religion_Catholic...\n",
            " -> Done. Magnitude: 2.2539\n",
            "Processing: Religion_Protestant...\n",
            " -> Done. Magnitude: 2.0098\n",
            "Processing: Religion_person of other religion...\n",
            " -> Done. Magnitude: 2.4434\n",
            "Processing: Religion_Jewish...\n",
            " -> Done. Magnitude: 1.9502\n",
            "Processing: PolViews_person with a slightly liberal political view...\n",
            " -> Done. Magnitude: 2.7617\n",
            "Processing: PolViews_person with a conservative political view...\n",
            " -> Done. Magnitude: 3.1426\n",
            "Processing: PolViews_person with a liberal political view...\n",
            " -> Done. Magnitude: 3.0254\n",
            "Processing: PolViews_person with a neutral political view...\n",
            " -> Done. Magnitude: 2.0469\n",
            "Processing: PolViews_person with a slightly conservative political view...\n",
            " -> Done. Magnitude: 2.9688\n",
            "Processing: PolViews_person with an extremely liberal political view...\n",
            " -> Done. Magnitude: 3.6895\n",
            "Processing: PolViews_person with an extremely conservative political view...\n",
            " -> Done. Magnitude: 3.8105\n",
            "Processing: Generation_person from Generation X...\n",
            " -> Done. Magnitude: 2.0469\n",
            "Processing: Generation_person from the Silent Generation...\n",
            " -> Done. Magnitude: 3.0391\n",
            "Processing: Generation_Baby Boomer...\n",
            " -> Done. Magnitude: 2.2930\n",
            "Processing: Generation_Millennial...\n",
            " -> Done. Magnitude: 1.7588\n",
            "Processing: Generation_person from Generation Z...\n",
            " -> Done. Magnitude: 1.9863\n",
            "\n",
            "All vectors saved to vectors/gss_demogaphic_vectors.pt.\n"
          ]
        }
      ],
      "source": [
        "# Extraction Loop (main)\n",
        "print(f\"Starting extraction on Layer {TARGET_LAYER}...\")\n",
        "\n",
        "# Iterate through every group created\n",
        "for label, pairs in extraction_datasets.items():\n",
        "    print(f\"Processing: {label}...\")\n",
        "\n",
        "    # Unzip the pairs into two lists: Positives and Negatives\n",
        "    # pairs is [(pos1, neg1), (pos2, neg2), ...]\n",
        "    pos_texts = [p[0] for p in pairs]\n",
        "    neg_texts = [p[1] for p in pairs]\n",
        "\n",
        "    # 1. Get activations for X+\n",
        "    pos_acts = []\n",
        "    for text in pos_texts:\n",
        "        act = get_layer_activations(model, tokenizer, text, TARGET_LAYER)\n",
        "        pos_acts.append(act)\n",
        "\n",
        "    # 2. Get activations for X-\n",
        "    neg_acts = []\n",
        "    for text in neg_texts:\n",
        "        act = get_layer_activations(model, tokenizer, text, TARGET_LAYER)\n",
        "        neg_acts.append(act)\n",
        "\n",
        "    # 3. Stack and compute mean (shape becomes [num_prompts, hidden_dim])\n",
        "    pos_tensor = torch.vstack(pos_acts)\n",
        "    neg_tensor = torch.vstack(neg_acts)\n",
        "\n",
        "    # 4. Calculate the difference vector (mean(Pos) - mean(Neg))\n",
        "    diff_vector = torch.mean(pos_tensor, dim=0) - torch.mean(neg_tensor, dim=0)\n",
        "\n",
        "    # 5. Normalize\n",
        "    raw_magnitude = torch.norm(diff_vector).item()\n",
        "    normalized_vector = diff_vector / torch.norm(diff_vector)\n",
        "\n",
        "    # 6. Store result\n",
        "    demographic_vectors[label] = {\n",
        "        \"vector\": normalized_vector,\n",
        "        \"magnitude\": raw_magnitude\n",
        "    }\n",
        "\n",
        "    print(f\" -> Done. Magnitude: {raw_magnitude:.4f}\")\n",
        "\n",
        "# Save results\n",
        "save_path = os.path.join(SAVE_DIR, \"gss_demogaphic_vectors.pt\")\n",
        "torch.save(demographic_vectors, save_path)\n",
        "print(f\"\\nAll vectors saved to {save_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "87d3d3ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87d3d3ce",
        "outputId": "8f5072da-8fef-4616-9070-2abd8aa462c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SANITY CHECK ---\n",
            "Democrat vs Republican Similarity: 0.8979 (Expect Negative)\n",
            "Black vs Republican Similarity:    0.5493 (Expect Near Zero)\n"
          ]
        }
      ],
      "source": [
        "# Verification\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def check_similarity(label_a, label_b):\n",
        "    if label_a not in demographic_vectors or label_b not in demographic_vectors:\n",
        "        print(f\"Labels not found.\")\n",
        "        return\n",
        "\n",
        "    vec_a = demographic_vectors[label_a][\"vector\"]\n",
        "    vec_b = demographic_vectors[label_b][\"vector\"]\n",
        "\n",
        "    # Compute Cosine Similarity\n",
        "    sim = F.cosine_similarity(vec_a.unsqueeze(0), vec_b.unsqueeze(0))\n",
        "    return sim.item()\n",
        "\n",
        "print(\"\\n--- SANITY CHECK ---\")\n",
        "# 1. Check Polarization (Should be negative)\n",
        "sim_pol = check_similarity(\"PartyID_Strong Democrat\", \"PartyID_Strong Republican\")\n",
        "print(f\"Democrat vs Republican Similarity: {sim_pol:.4f} (Expect Negative)\")\n",
        "\n",
        "# 2. Check Unrelated traits (Should be near zero)\n",
        "sim_rand = check_similarity(\"Race_Black person\", \"PartyID_Strong Republican\")\n",
        "print(f\"Black vs Republican Similarity:    {sim_rand:.4f} (Expect Near Zero)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aed8059e",
      "metadata": {
        "id": "aed8059e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4919d734",
      "metadata": {
        "id": "4919d734"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379480e1",
      "metadata": {
        "id": "379480e1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9765b7ab",
      "metadata": {
        "id": "9765b7ab"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1380a9a63002401bbbd75626406d9b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5e0f351609242eba95b0b266455a525",
              "IPY_MODEL_79845bc10ff64373af8a6609bce21ba8",
              "IPY_MODEL_62c5d7c54e244f4383a6c8503f1bedeb"
            ],
            "layout": "IPY_MODEL_70cecb9a639d47c99ab63391ab8d7f0d"
          }
        },
        "f5e0f351609242eba95b0b266455a525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc9fb7b84b94a6cafeceae506f4dd28",
            "placeholder": "​",
            "style": "IPY_MODEL_7665d9dca6514024bc3c031f95430598",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "79845bc10ff64373af8a6609bce21ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077fa8bace94494293f732ce1a3420f7",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b16a016f499e496f958895ab602b7a6b",
            "value": 4
          }
        },
        "62c5d7c54e244f4383a6c8503f1bedeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303c89512b0844b1aecd5b531c50f880",
            "placeholder": "​",
            "style": "IPY_MODEL_1df64d6fff8f46bdb3c35733438b5cef",
            "value": " 4/4 [00:16&lt;00:00,  3.56s/it]"
          }
        },
        "70cecb9a639d47c99ab63391ab8d7f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc9fb7b84b94a6cafeceae506f4dd28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7665d9dca6514024bc3c031f95430598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077fa8bace94494293f732ce1a3420f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16a016f499e496f958895ab602b7a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "303c89512b0844b1aecd5b531c50f880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df64d6fff8f46bdb3c35733438b5cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}