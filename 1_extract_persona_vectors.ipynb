{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-0",
   "source": [
    "<a href=\"https://colab.research.google.com/github/yilmajung/belief_and_llms_v0/blob/main/1_extract_persona_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-0a",
   "source": "# Phase 1: Extract Persona Vectors (Layers 5-20)\n\nThis notebook extracts demographic steering vectors from **multiple layers (5-20)** of Meta-Llama-3-8B-Instruct.\n\n**Output:** One vector file per layer:\n- `gss_demographic_vectors_layer5.pt`\n- `gss_demographic_vectors_layer6.pt`\n- ...\n- `gss_demographic_vectors_layer20.pt`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "qdMB_uZITACH",
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "6a7d1584",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "Bl2ZbmOFl_eB",
   "outputs": [],
   "source": [
    "# Link to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "54bf7cce",
   "outputs": [],
   "source": [
    "# Load extraction_datasets.json\n",
    "import json\n",
    "with open(\"/content/drive/MyDrive/belief_and_llms_v0/gss_extraction_datasets.json\", \"r\") as f:\n",
    "    extraction_datasets = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(extraction_datasets)} demographic groups.\")\n",
    "print(\"Groups:\", list(extraction_datasets.keys())[:5], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "f10a62f9",
   "outputs": [],
   "source": "# Model Setup\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n\n# Load model in 4-bit to save memory\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    load_in_4bit=True,\n    device_map=\"auto\",\n    torch_dtype=torch.float16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n# Configuration: Layers to extract\nLAYERS_TO_EXTRACT = list(range(5, 21))  # Layers 5, 6, 7, ..., 20\nSAVE_DIR = \"/content/drive/MyDrive/belief_and_llms_v0/vectors\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n\nprint(f\"Will extract vectors from layers: {LAYERS_TO_EXTRACT}\")\nprint(f\"Save directory: {SAVE_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "f4860d8b",
   "outputs": [],
   "source": [
    "# Helper: Hook Function\n",
    "\n",
    "def get_layer_activations(model, tokenizer, inputs_text, layer_idx):\n",
    "    \"\"\"\n",
    "    Extract hidden state activations at a specific layer.\n",
    "    Returns the activation at the last token position.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(inputs_text, return_tensors=\"pt\").to(model.device)\n",
    "    captured_hidden = None\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        nonlocal captured_hidden\n",
    "\n",
    "        # Unwrap tuple if needed\n",
    "        if isinstance(output, tuple):\n",
    "            h_states = output[0]\n",
    "        else:\n",
    "            h_states = output\n",
    "\n",
    "        # Handle different tensor shapes\n",
    "        if h_states.dim() == 3:\n",
    "            # [Batch, Seq, Hidden] -> take last token\n",
    "            captured_hidden = h_states[0, -1, :].detach().cpu()\n",
    "        elif h_states.dim() == 2:\n",
    "            # [Seq, Hidden] -> take last token\n",
    "            captured_hidden = h_states[-1, :].detach().cpu()\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected tensor shape: {h_states.shape}\")\n",
    "\n",
    "    # Register hook and run forward pass\n",
    "    layer = model.model.layers[layer_idx]\n",
    "    handle = layer.register_forward_hook(hook_fn)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model(**inputs)\n",
    "\n",
    "    handle.remove()\n",
    "    return captured_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "e89ca900",
   "outputs": [],
   "source": [
    "def extract_vectors_for_layer(model, tokenizer, extraction_datasets, layer_idx):\n",
    "    \"\"\"\n",
    "    Extract all demographic vectors for a single layer.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {demographic_label: {'vector': tensor, 'magnitude': float}}\n",
    "    \"\"\"\n",
    "    demographic_vectors = {}\n",
    "    \n",
    "    for label, pairs in extraction_datasets.items():\n",
    "        # Unzip pairs into positive and negative texts\n",
    "        pos_texts = [p[0] for p in pairs]\n",
    "        neg_texts = [p[1] for p in pairs]\n",
    "\n",
    "        # Get activations for X+ (persona)\n",
    "        pos_acts = []\n",
    "        for text in pos_texts:\n",
    "            act = get_layer_activations(model, tokenizer, text, layer_idx)\n",
    "            pos_acts.append(act)\n",
    "\n",
    "        # Get activations for X- (baseline)\n",
    "        neg_acts = []\n",
    "        for text in neg_texts:\n",
    "            act = get_layer_activations(model, tokenizer, text, layer_idx)\n",
    "            neg_acts.append(act)\n",
    "\n",
    "        # Stack and compute mean\n",
    "        pos_tensor = torch.vstack(pos_acts)\n",
    "        neg_tensor = torch.vstack(neg_acts)\n",
    "\n",
    "        # Calculate difference vector: mean(X+) - mean(X-)\n",
    "        diff_vector = torch.mean(pos_tensor, dim=0) - torch.mean(neg_tensor, dim=0)\n",
    "\n",
    "        # Normalize\n",
    "        raw_magnitude = torch.norm(diff_vector).item()\n",
    "        if raw_magnitude > 0:\n",
    "            normalized_vector = diff_vector / torch.norm(diff_vector)\n",
    "        else:\n",
    "            normalized_vector = diff_vector  # Keep zero vector as is\n",
    "\n",
    "        # Store result\n",
    "        demographic_vectors[label] = {\n",
    "            \"vector\": normalized_vector,\n",
    "            \"magnitude\": raw_magnitude\n",
    "        }\n",
    "\n",
    "    return demographic_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "extraction-loop",
   "outputs": [],
   "source": [
    "# Main Extraction Loop: Extract vectors for ALL layers\n",
    "\n",
    "all_layer_vectors = {}  # Store all results in memory\n",
    "\n",
    "for layer_idx in LAYERS_TO_EXTRACT:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Extracting vectors from Layer {layer_idx}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Extract vectors for this layer\n",
    "    vectors = extract_vectors_for_layer(model, tokenizer, extraction_datasets, layer_idx)\n",
    "    \n",
    "    # Store in memory\n",
    "    all_layer_vectors[layer_idx] = vectors\n",
    "    \n",
    "    # Save to file\n",
    "    save_path = os.path.join(SAVE_DIR, f\"gss_demographic_vectors_layer{layer_idx}.pt\")\n",
    "    torch.save(vectors, save_path)\n",
    "    \n",
    "    # Print summary\n",
    "    magnitudes = [v['magnitude'] for v in vectors.values()]\n",
    "    print(f\"  Saved {len(vectors)} vectors to {save_path}\")\n",
    "    print(f\"  Magnitude range: {min(magnitudes):.4f} - {max(magnitudes):.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EXTRACTION COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Extracted vectors from {len(LAYERS_TO_EXTRACT)} layers.\")\n",
    "print(f\"Files saved to: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-verification",
   "source": [
    "## Verification: Sanity Checks Across Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "verification",
   "outputs": [],
   "source": [
    "# Verify: Check Democrat vs Republican similarity across layers\n",
    "\n",
    "def check_similarity(vectors_dict, label_a, label_b):\n",
    "    \"\"\"Compute cosine similarity between two demographic vectors.\"\"\"\n",
    "    if label_a not in vectors_dict or label_b not in vectors_dict:\n",
    "        return None\n",
    "    vec_a = vectors_dict[label_a][\"vector\"]\n",
    "    vec_b = vectors_dict[label_b][\"vector\"]\n",
    "    return F.cosine_similarity(vec_a.unsqueeze(0), vec_b.unsqueeze(0)).item()\n",
    "\n",
    "print(\"\\n--- SANITY CHECK: Democrat vs Republican Across Layers ---\")\n",
    "print(f\"{'Layer':<8} | {'Dem vs Rep':<12} | {'Black vs Rep':<12}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for layer_idx in LAYERS_TO_EXTRACT:\n",
    "    vectors = all_layer_vectors[layer_idx]\n",
    "    sim_pol = check_similarity(vectors, \"PartyID_Strong Democrat\", \"PartyID_Strong Republican\")\n",
    "    sim_race = check_similarity(vectors, \"Race_Black person\", \"PartyID_Strong Republican\")\n",
    "    print(f\"{layer_idx:<8} | {sim_pol:+.4f}      | {sim_race:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-viz",
   "source": [
    "## Visualization: Compare Vector Magnitudes Across Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "viz-magnitudes",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Build DataFrame of magnitudes\n",
    "magnitude_data = []\n",
    "for layer_idx in LAYERS_TO_EXTRACT:\n",
    "    vectors = all_layer_vectors[layer_idx]\n",
    "    for label, data in vectors.items():\n",
    "        magnitude_data.append({\n",
    "            'layer': layer_idx,\n",
    "            'demographic': label,\n",
    "            'category': label.split('_')[0],\n",
    "            'magnitude': data['magnitude']\n",
    "        })\n",
    "\n",
    "df_mag = pd.DataFrame(magnitude_data)\n",
    "\n",
    "# Plot: Average magnitude by layer\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "avg_by_layer = df_mag.groupby('layer')['magnitude'].mean()\n",
    "plt.plot(avg_by_layer.index, avg_by_layer.values, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Layer', fontsize=12)\n",
    "plt.ylabel('Average Magnitude', fontsize=12)\n",
    "plt.title('Average Vector Magnitude by Layer', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Heatmap: magnitude by demographic and layer\n",
    "pivot = df_mag.pivot(index='demographic', columns='layer', values='magnitude')\n",
    "# Show only a subset for readability\n",
    "sample_demos = ['PartyID_Strong Republican', 'PartyID_Strong Democrat', \n",
    "                'Race_Black person', 'Race_White person',\n",
    "                'PolViews_person with a conservative political view',\n",
    "                'PolViews_person with a liberal political view']\n",
    "pivot_subset = pivot.loc[[d for d in sample_demos if d in pivot.index]]\n",
    "sns.heatmap(pivot_subset, cmap='YlOrRd', annot=True, fmt='.2f')\n",
    "plt.title('Magnitude by Demographic & Layer', fontsize=14)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-pca",
   "source": [
    "## PCA Visualization for Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "pca-viz",
   "outputs": [],
   "source": "from sklearn.decomposition import PCA\n\n# Create PCA plots for layers 5, 12, and 20\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor idx, layer_idx in enumerate([5, 12, 20]):\n    vectors = all_layer_vectors[layer_idx]\n    \n    # Prepare data\n    labels = []\n    vectors_list = []\n    categories = []\n    \n    for key, data in vectors.items():\n        vec = data['vector'].cpu().numpy()\n        if not (np.isnan(vec).any() or np.isinf(vec).any()):\n            vectors_list.append(vec)\n            labels.append(key)\n            categories.append(key.split('_')[0])\n    \n    X = np.array(vectors_list)\n    \n    # PCA\n    pca = PCA(n_components=2)\n    X_2d = pca.fit_transform(X)\n    \n    # Plot\n    ax = axes[idx]\n    df_plot = pd.DataFrame({\n        'x': X_2d[:, 0],\n        'y': X_2d[:, 1],\n        'category': categories\n    })\n    \n    for cat in df_plot['category'].unique():\n        mask = df_plot['category'] == cat\n        ax.scatter(df_plot.loc[mask, 'x'], df_plot.loc[mask, 'y'], \n                   label=cat, alpha=0.7, s=100)\n    \n    ax.axhline(0, color='black', linestyle='--', alpha=0.3)\n    ax.axvline(0, color='black', linestyle='--', alpha=0.3)\n    ax.set_title(f'Layer {layer_idx}', fontsize=14)\n    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n    if idx == 2:\n        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.suptitle('PCA of Demographic Vectors Across Layers', fontsize=16)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-summary",
   "source": "## Summary\n\nThis notebook extracted demographic steering vectors from layers 5-20.\n\n**Output files:**\n```\nvectors/\n├── gss_demographic_vectors_layer5.pt\n├── gss_demographic_vectors_layer6.pt\n├── ...\n└── gss_demographic_vectors_layer20.pt\n```\n\n**Next steps:**\n- Use `2_simulate_steering_vectors.ipynb` to test steering effectiveness\n- Use `3_investigate_correlations.ipynb` to analyze how steering affects other demographics\n\n**Important:** For steering experiments, always use vectors extracted at the SAME layer as the injection layer."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}