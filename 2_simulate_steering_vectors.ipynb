{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe98557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demographic_vectors\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 1. SETUP PATH\n",
    "# Ensure this matches the SAVE_DIR and filename you used in Phase 1\n",
    "file_path = os.path.join(\"/content/drive/MyDrive/belief_and_llms_v0/vectors\", \"gss_demographic_vectors.pt\")\n",
    "\n",
    "\n",
    "# 2. LOAD THE FILE\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Loading vectors from {file_path}...\")\n",
    "    \n",
    "    # map_location='cpu' ensures it loads even if you don't have a GPU right now,\n",
    "    # or if the vectors were saved on a GPU different from the current one.\n",
    "    demographic_vectors = torch.load(file_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    print(f\"Success! Loaded {len(demographic_vectors)} vectors.\")\n",
    "    \n",
    "    # Print the keys to remind what I have\n",
    "    print(\"\\nAvailable Vectors:\")\n",
    "    for key in list(demographic_vectors.keys())[:10]: # Print first 10\n",
    "        print(f\" - {key}\")\n",
    "else:\n",
    "    print(f\"Error: File not found at {file_path}. Did you run the extraction code?\")\n",
    "\n",
    "\n",
    "# 3. HOW TO USE A VECTOR FOR STEERING\n",
    "# Example: Getting the Republican vector for the steering experiment\n",
    "target_label = \"Party_Strong Republican\"\n",
    "\n",
    "if target_label in demographic_vectors:\n",
    "    # CRITICAL: The saved object is a dictionary {'vector': ..., 'magnitude': ...}\n",
    "    # Need to extract just the tensor stored in 'vector'\n",
    "    steering_vector = demographic_vectors[target_label][\"vector\"]\n",
    "    steering_vector = steering_vector.to(\"cuda\") \n",
    "    \n",
    "    print(f\"\\nRetrieved '{target_label}'. Shape: {steering_vector.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# Choose the vector to test\n",
    "TARGET_LABEL = \"Party_Strong Republican\" \n",
    "TARGET_LAYER = 15  # Must match the layer you extracted from!\n",
    "\n",
    "# Define the Probe Question\n",
    "# Use a zero-shot prompt asking for an opinion.\n",
    "probe_prompt = \"[INST] What is your stance on abortion? Please answer in one sentence. [/INST]\"\n",
    "\n",
    "# Define the Strengths to test\n",
    "# 0 = Control (Normal Model)\n",
    "# Positive = Make it MORE Republican\n",
    "# Negative = Make it LESS Republican (Inverse steering)\n",
    "strengths = [-2.0, -1.0, 0.0, 1.0, 2.0, 3.0]\n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD THE VECTOR\n",
    "# ==========================================\n",
    "# Assuming 'demographic_vectors' dict exists in memory from Phase 1.\n",
    "# If you loaded from file: demographic_vectors = torch.load(\"vectors/gss_demographic_vectors.pt\")\n",
    "\n",
    "if TARGET_LABEL not in demographic_vectors:\n",
    "    raise ValueError(f\"Vector '{TARGET_LABEL}' not found. Check your dictionary keys.\")\n",
    "\n",
    "# Get vector and ensure it's on the right device/dtype\n",
    "steering_vector = demographic_vectors[TARGET_LABEL][\"vector\"].to(model.device).to(model.dtype)\n",
    "\n",
    "# ==========================================\n",
    "# 3. THE STEERING FUNCTION\n",
    "# ==========================================\n",
    "def generate_with_steering(prompt, vector, strength, layer_idx):\n",
    "    \"\"\"\n",
    "    Generates text while adding (strength * vector) to the hidden states.\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Define the Hook\n",
    "    def steering_hook(module, input, output):\n",
    "        # output[0] is the hidden state tensor: (batch, seq_len, hidden_dim)\n",
    "        # We add the vector to ALL tokens in the prompt.\n",
    "        # This biases the model's \"mood\" for the entire generation.\n",
    "        \n",
    "        # Reshape vector to (1, 1, hidden_dim) for broadcasting\n",
    "        perturbation = vector.view(1, 1, -1) * strength\n",
    "        \n",
    "        # Add to the hidden state\n",
    "        return (output[0] + perturbation, output[1])\n",
    "\n",
    "    # Register the hook to the specific layer\n",
    "    layer = model.model.layers[layer_idx]\n",
    "    handle = layer.register_forward_hook(steering_hook)\n",
    "    \n",
    "    # Generate Response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=60,      # Keep it short\n",
    "            do_sample=False,        # Greedy decoding (deterministic)\n",
    "            temperature=None,\n",
    "            top_p=None,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Remove hook immediately\n",
    "    handle.remove()\n",
    "    \n",
    "    # Decode\n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract just the response (remove the prompt)\n",
    "    response = full_text.replace(prompt, \"\").strip()\n",
    "    return response\n",
    "\n",
    "# ==========================================\n",
    "# 4. RUN THE EXPERIMENT\n",
    "# ==========================================\n",
    "results = []\n",
    "\n",
    "print(f\"--- STEERING EXPERIMENT: {TARGET_LABEL} ---\")\n",
    "print(f\"Prompt: {probe_prompt}\\n\")\n",
    "\n",
    "for alpha in strengths:\n",
    "    response = generate_with_steering(probe_prompt, steering_vector, alpha, TARGET_LAYER)\n",
    "    \n",
    "    print(f\"Strength {alpha:+.1f}: {response}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"Vector\": TARGET_LABEL,\n",
    "        \"Strength\": alpha,\n",
    "        \"Response\": response\n",
    "    })\n",
    "\n",
    "# ==========================================\n",
    "# 5. SAVE RESULTS TO DATAFRAME\n",
    "# ==========================================\n",
    "df_steering = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b237e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belief_llms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
