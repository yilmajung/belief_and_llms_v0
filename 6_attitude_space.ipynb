{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: Attitude Space\n",
    "\n",
    "Building an **Attitude Space** parallel to the Demographic Space (Phase 5/5.1).\n",
    "\n",
    "We extract steering vectors for **~96 attitude positions** across **34 social-issue variables**\n",
    "from the GSS, then apply within-category centering and PCA to discover interpretable axes of\n",
    "attitudinal variation.\n",
    "\n",
    "**Key design decisions:**\n",
    "- All response options kept (not binary-collapsed). 7-point Likert scales collapsed to 3 meaningful groups.\n",
    "- Shared baseline: all positions use the same \"person\" baseline. X- mean computed ONCE per layer.\n",
    "- Same 5 neutral Q&A pairs as demographic extraction (Phase 1).\n",
    "- Categories = GSS variable names (34 total). Within-category centering removes shared \"attitude-ness\".\n",
    "\n",
    "**Pipeline:**\n",
    "1. Define 34 attitude variables with ~96 positions (response options)\n",
    "2. Generate contrastive prompts (attitude persona vs generic baseline)\n",
    "3. Extract vectors from Llama-3 layers 5-20 (shared baseline optimization)\n",
    "4. PCA on centered attitude vectors \u2192 Attitude Space\n",
    "5. Cross-space comparison with Demographic Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib.cm import get_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_DIR = '/content/drive/MyDrive/belief_and_llms_v0'\n",
    "except ImportError:\n",
    "    BASE_DIR = '.'\n",
    "\n",
    "VECTOR_DIR = os.path.join(BASE_DIR, 'vectors')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "os.makedirs(VECTOR_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "LAYERS_TO_EXTRACT = list(range(5, 21))\n",
    "\n",
    "print(f'Model loaded: {model_name}')\n",
    "print(f'Layers to extract: {LAYERS_TO_EXTRACT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each category maps to a list of natural-language persona labels.\n",
    "# Format: {GSS_variable_name: [position_label_1, position_label_2, ...]}\n",
    "# Labels are used directly in prompts: \"You are a (an) {label} living in the United States.\"\n",
    "\n",
    "attitude_maps = {\n",
    "    # \u2500\u2500 4 Existing Social Issues (8 positions) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    'Abortion': [\n",
    "        'pro-choice person',\n",
    "        'pro-life person',\n",
    "    ],\n",
    "    'GunControl': [\n",
    "        'person who supports stricter gun control',\n",
    "        'person who supports gun rights',\n",
    "    ],\n",
    "    'SameSexMarriage': [\n",
    "        'person who supports same-sex marriage',\n",
    "        'person who opposes same-sex marriage',\n",
    "    ],\n",
    "    'DeathPenalty': [\n",
    "        'person who favors the death penalty',\n",
    "        'person who opposes the death penalty',\n",
    "    ],\n",
    "\n",
    "    # \u2500\u2500 8 Government Spending Variables (24 positions) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    'natspac': [\n",
    "        'person who thinks we spend too little on space exploration',\n",
    "        'person who thinks we spend about the right amount on space exploration',\n",
    "        'person who thinks we spend too much on space exploration',\n",
    "    ],\n",
    "    'natenvir': [\n",
    "        'person who thinks we spend too little on the environment',\n",
    "        'person who thinks we spend about the right amount on the environment',\n",
    "        'person who thinks we spend too much on the environment',\n",
    "    ],\n",
    "    'natcrime': [\n",
    "        'person who thinks we spend too little on crime prevention',\n",
    "        'person who thinks we spend about the right amount on crime prevention',\n",
    "        'person who thinks we spend too much on crime prevention',\n",
    "    ],\n",
    "    'natdrug': [\n",
    "        'person who thinks we spend too little on drug rehabilitation',\n",
    "        'person who thinks we spend about the right amount on drug rehabilitation',\n",
    "        'person who thinks we spend too much on drug rehabilitation',\n",
    "    ],\n",
    "    'nateduc': [\n",
    "        'person who thinks we spend too little on education',\n",
    "        'person who thinks we spend about the right amount on education',\n",
    "        'person who thinks we spend too much on education',\n",
    "    ],\n",
    "    'natrace': [\n",
    "        'person who thinks we spend too little on improving the conditions of Black Americans',\n",
    "        'person who thinks we spend about the right amount on improving the conditions of Black Americans',\n",
    "        'person who thinks we spend too much on improving the conditions of Black Americans',\n",
    "    ],\n",
    "    'natarms': [\n",
    "        'person who thinks we spend too little on the military and defense',\n",
    "        'person who thinks we spend about the right amount on the military and defense',\n",
    "        'person who thinks we spend too much on the military and defense',\n",
    "    ],\n",
    "    'natfare': [\n",
    "        'person who thinks we spend too little on welfare',\n",
    "        'person who thinks we spend about the right amount on welfare',\n",
    "        'person who thinks we spend too much on welfare',\n",
    "    ],\n",
    "\n",
    "    # \u2500\u2500 22 Other Attitude Variables (64 positions) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "    'eqwlth': [\n",
    "        'person who believes government should reduce income differences',\n",
    "        'person who is neutral on whether government should reduce income differences',\n",
    "        'person who believes government should not concern itself with income differences',\n",
    "    ],\n",
    "    'courts': [\n",
    "        'person who thinks courts are too harsh on criminals',\n",
    "        'person who thinks courts are about right on criminals',\n",
    "        'person who thinks courts are not harsh enough on criminals',\n",
    "    ],\n",
    "    'librac': [\n",
    "        'person who believes a racist should be allowed to speak publicly',\n",
    "        'person who believes a racist should not be allowed to speak publicly',\n",
    "    ],\n",
    "    'libath': [\n",
    "        'person who believes an atheist should be allowed to speak publicly',\n",
    "        'person who believes an atheist should not be allowed to speak publicly',\n",
    "    ],\n",
    "    'grass': [\n",
    "        'person who thinks marijuana should be legal',\n",
    "        'person who thinks marijuana should not be legal',\n",
    "    ],\n",
    "    'bible': [\n",
    "        'person who believes the Bible is the literal word of God',\n",
    "        'person who believes the Bible is the inspired word of God but not literal',\n",
    "        'person who believes the Bible is a book of fables',\n",
    "    ],\n",
    "    'world1': [\n",
    "        'person who believes the world is fundamentally good',\n",
    "        'person who believes the world is neither good nor evil',\n",
    "        'person who believes the world is fundamentally evil',\n",
    "    ],\n",
    "    'world4': [\n",
    "        'person who believes people are fundamentally good',\n",
    "        'person who believes people are neither good nor evil',\n",
    "        'person who believes people are fundamentally evil',\n",
    "    ],\n",
    "    'racopen': [\n",
    "        'person who believes a homeowner should have the right to refuse to sell to someone of a different race',\n",
    "        'person who believes a homeowner should not be allowed to discriminate in selling their home',\n",
    "    ],\n",
    "    'affrmact': [\n",
    "        'person who strongly favors affirmative action',\n",
    "        'person who favors affirmative action',\n",
    "        'person who opposes affirmative action',\n",
    "        'person who strongly opposes affirmative action',\n",
    "    ],\n",
    "    'trust': [\n",
    "        'person who believes most people can be trusted',\n",
    "        'person who believes whether people can be trusted depends',\n",
    "        \"person who believes you can't be too careful with people\",\n",
    "    ],\n",
    "    'fair': [\n",
    "        'person who believes most people try to be fair',\n",
    "        'person who believes whether people are fair depends',\n",
    "        'person who believes most people try to take advantage',\n",
    "    ],\n",
    "    'richwork': [\n",
    "        'person who would continue working if rich',\n",
    "        'person who would stop working if rich',\n",
    "    ],\n",
    "    'premarsx': [\n",
    "        'person who thinks premarital sex is not wrong at all',\n",
    "        'person who thinks premarital sex is sometimes wrong',\n",
    "        'person who thinks premarital sex is almost always wrong',\n",
    "        'person who thinks premarital sex is always wrong',\n",
    "    ],\n",
    "    'xmarsex': [\n",
    "        'person who thinks extramarital sex is not wrong at all',\n",
    "        'person who thinks extramarital sex is sometimes wrong',\n",
    "        'person who thinks extramarital sex is almost always wrong',\n",
    "        'person who thinks extramarital sex is always wrong',\n",
    "    ],\n",
    "    'letdie1': [\n",
    "        'person who believes a terminally ill patient should have the right to die',\n",
    "        'person who believes a terminally ill patient should not have the right to die',\n",
    "    ],\n",
    "    'spanking': [\n",
    "        'person who strongly agrees that spanking is appropriate',\n",
    "        'person who agrees that spanking is appropriate',\n",
    "        'person who disagrees that spanking is appropriate',\n",
    "        'person who strongly disagrees that spanking is appropriate',\n",
    "    ],\n",
    "    'helppoor': [\n",
    "        'person who believes government should help the poor',\n",
    "        'person who has mixed views on government help for the poor',\n",
    "        'person who believes people should help themselves',\n",
    "    ],\n",
    "    'helpsick': [\n",
    "        'person who believes government should help pay for medical care',\n",
    "        'person who has mixed views on government help for medical care',\n",
    "        'person who believes people should pay for their own medical care',\n",
    "    ],\n",
    "    'workwhts': [\n",
    "        'person who perceives White people as generally hard-working',\n",
    "        'person who perceives White people as average in work ethic',\n",
    "        'person who perceives White people as generally lazy',\n",
    "    ],\n",
    "    'workblks': [\n",
    "        'person who perceives Black people as generally hard-working',\n",
    "        'person who perceives Black people as average in work ethic',\n",
    "        'person who perceives Black people as generally lazy',\n",
    "    ],\n",
    "    'workhsps': [\n",
    "        'person who perceives Hispanic people as generally hard-working',\n",
    "        'person who perceives Hispanic people as average in work ethic',\n",
    "        'person who perceives Hispanic people as generally lazy',\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Summary\n",
    "n_categories = len(attitude_maps)\n",
    "n_positions = sum(len(positions) for positions in attitude_maps.values())\n",
    "print(f'Attitude variables: {n_categories} categories, {n_positions} total positions')\n",
    "print()\n",
    "for cat, positions in attitude_maps.items():\n",
    "    print(f'  {cat:20s}: {len(positions)} positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same 5 neutral Q&A pairs used in demographic extraction (Phase 1)\n",
    "QA_PAIRS = [\n",
    "    ('Describe your morning routine.',\n",
    "     'I woke up, brushed my teeth, and had a cup of coffee before checking the news.'),\n",
    "    ('What are you having for lunch?',\n",
    "     \"I'm planning to have a sandwich and a salad at a local cafe.\"),\n",
    "    ('How is the weather today?',\n",
    "     'It is partly cloudy and a bit brisk, but the sun is peeking through.'),\n",
    "    ('What are your plans for the weekend?',\n",
    "     'I plan to relax at home, catch up on some reading, and maybe go for a walk.'),\n",
    "    ('Describe your commute.',\n",
    "     'I traveled to the city center and listened to a podcast on the way.'),\n",
    "]\n",
    "\n",
    "BASELINE_LABEL = 'person'\n",
    "\n",
    "\n",
    "def make_prompt(persona, question, answer):\n",
    "    return f'[INST] You are a (an) {persona} living in the United States. {question} [/INST] {answer}'\n",
    "\n",
    "\n",
    "# Build extraction datasets: {label: [[X+, X-], ...]}\n",
    "extraction_datasets = {}\n",
    "\n",
    "for category, positions in attitude_maps.items():\n",
    "    for position in positions:\n",
    "        label = f'{category}_{position}'\n",
    "        pairs = []\n",
    "        for q, a in QA_PAIRS:\n",
    "            pos_prompt = make_prompt(position, q, a)\n",
    "            neg_prompt = make_prompt(BASELINE_LABEL, q, a)\n",
    "            pairs.append([pos_prompt, neg_prompt])\n",
    "        extraction_datasets[label] = pairs\n",
    "\n",
    "# Baseline prompts (shared across all positions)\n",
    "baseline_prompts = [make_prompt(BASELINE_LABEL, q, a) for q, a in QA_PAIRS]\n",
    "\n",
    "print(f'Total attitude positions: {len(extraction_datasets)}')\n",
    "print(f'Prompt pairs per position: {len(QA_PAIRS)}')\n",
    "print(f'Baseline prompts: {len(baseline_prompts)}')\n",
    "\n",
    "# Save extraction datasets\n",
    "save_path = os.path.join(DATA_DIR, 'gss_attitude_extraction_datasets.json')\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(extraction_datasets, f, indent=4)\n",
    "print(f'Saved to {save_path}')\n",
    "\n",
    "# Print a sample\n",
    "sample_label = list(extraction_datasets.keys())[0]\n",
    "print(f'\\nSample ({sample_label}):')\n",
    "print(f'  X+: {extraction_datasets[sample_label][0][0][:100]}...')\n",
    "print(f'  X-: {extraction_datasets[sample_label][0][1][:100]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_activations(model, tokenizer, inputs_text, layer_idx):\n",
    "    \"\"\"Extract hidden state at last token position from a specific layer.\"\"\"\n",
    "    inputs = tokenizer(inputs_text, return_tensors='pt').to(model.device)\n",
    "    captured_hidden = None\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        nonlocal captured_hidden\n",
    "        if isinstance(output, tuple):\n",
    "            h_states = output[0]\n",
    "        else:\n",
    "            h_states = output\n",
    "        if h_states.dim() == 3:\n",
    "            captured_hidden = h_states[0, -1, :].detach().cpu()\n",
    "        elif h_states.dim() == 2:\n",
    "            captured_hidden = h_states[-1, :].detach().cpu()\n",
    "        else:\n",
    "            raise ValueError(f'Unexpected tensor shape: {h_states.shape}')\n",
    "\n",
    "    layer = model.model.layers[layer_idx]\n",
    "    handle = layer.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(**inputs)\n",
    "    handle.remove()\n",
    "    return captured_hidden\n",
    "\n",
    "\n",
    "def compute_baseline_mean(model, tokenizer, baseline_prompts, layer_idx):\n",
    "    \"\"\"Compute mean activation for shared baseline prompts.\"\"\"\n",
    "    acts = []\n",
    "    for text in baseline_prompts:\n",
    "        act = get_layer_activations(model, tokenizer, text, layer_idx)\n",
    "        acts.append(act)\n",
    "    return torch.mean(torch.vstack(acts), dim=0)\n",
    "\n",
    "\n",
    "def extract_attitude_vectors(model, tokenizer, extraction_datasets, layer_idx, baseline_mean):\n",
    "    \"\"\"\n",
    "    Extract attitude vectors for a single layer using precomputed baseline mean.\n",
    "\n",
    "    Returns: {label: {'vector': normalized_tensor, 'magnitude': float}}\n",
    "    \"\"\"\n",
    "    attitude_vectors = {}\n",
    "\n",
    "    for label, pairs in extraction_datasets.items():\n",
    "        pos_texts = [p[0] for p in pairs]\n",
    "\n",
    "        pos_acts = []\n",
    "        for text in pos_texts:\n",
    "            act = get_layer_activations(model, tokenizer, text, layer_idx)\n",
    "            pos_acts.append(act)\n",
    "\n",
    "        pos_mean = torch.mean(torch.vstack(pos_acts), dim=0)\n",
    "        diff_vector = pos_mean - baseline_mean\n",
    "\n",
    "        raw_magnitude = torch.norm(diff_vector).item()\n",
    "        if raw_magnitude > 0:\n",
    "            normalized_vector = diff_vector / torch.norm(diff_vector)\n",
    "        else:\n",
    "            normalized_vector = diff_vector\n",
    "\n",
    "        attitude_vectors[label] = {\n",
    "            'vector': normalized_vector,\n",
    "            'magnitude': raw_magnitude,\n",
    "        }\n",
    "\n",
    "    return attitude_vectors\n",
    "\n",
    "print('Extraction functions defined.')\n",
    "print(f'  Shared baseline optimization: X- computed once per layer ({len(baseline_prompts)} prompts)')\n",
    "print(f'  Per-position forward passes: {len(QA_PAIRS)} (X+ only)')\n",
    "print(f'  Total forward passes per layer: {len(baseline_prompts)} + {len(extraction_datasets)} * {len(QA_PAIRS)} = {len(baseline_prompts) + len(extraction_datasets) * len(QA_PAIRS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Extracting attitude vectors across layers {LAYERS_TO_EXTRACT}')\n",
    "print(f'Positions: {len(extraction_datasets)}, Prompts per position: {len(QA_PAIRS)}')\n",
    "print(f'Baseline computed ONCE per layer ({len(baseline_prompts)} prompts)')\n",
    "print()\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "for layer_idx in LAYERS_TO_EXTRACT:\n",
    "    layer_start = time.time()\n",
    "\n",
    "    # Compute baseline mean once for this layer\n",
    "    baseline_mean = compute_baseline_mean(model, tokenizer, baseline_prompts, layer_idx)\n",
    "\n",
    "    # Extract all attitude vectors using shared baseline\n",
    "    vectors = extract_attitude_vectors(\n",
    "        model, tokenizer, extraction_datasets, layer_idx, baseline_mean\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    save_path = os.path.join(VECTOR_DIR, f'gss_attitude_vectors_layer{layer_idx}.pt')\n",
    "    torch.save(vectors, save_path)\n",
    "\n",
    "    elapsed = time.time() - layer_start\n",
    "    print(f'Layer {layer_idx:2d}: {len(vectors)} vectors saved ({elapsed:.1f}s)')\n",
    "\n",
    "total_elapsed = time.time() - total_start\n",
    "print(f'\\nTotal extraction time: {total_elapsed / 60:.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_LAYER = 13\n",
    "\n",
    "vectors = torch.load(\n",
    "    os.path.join(VECTOR_DIR, f'gss_attitude_vectors_layer{REF_LAYER}.pt'),\n",
    "    map_location='cpu',\n",
    "    weights_only=True,\n",
    ")\n",
    "\n",
    "labels = sorted(vectors.keys())\n",
    "categories = [lab.split('_')[0] for lab in labels]\n",
    "unique_cats = sorted(set(categories))\n",
    "\n",
    "magnitudes = np.array([vectors[lab]['magnitude'] for lab in labels])\n",
    "\n",
    "print(f'Layer {REF_LAYER}: {len(vectors)} attitude vectors')\n",
    "print(f'Vector dimension: {vectors[labels[0]][\"vector\"].shape[0]}')\n",
    "print(f'Categories: {len(unique_cats)}')\n",
    "print(f'\\nMagnitude statistics:')\n",
    "print(f'  Mean: {magnitudes.mean():.4f}')\n",
    "print(f'  Std:  {magnitudes.std():.4f}')\n",
    "print(f'  Min:  {magnitudes.min():.4f}  ({labels[np.argmin(magnitudes)]})')\n",
    "print(f'  Max:  {magnitudes.max():.4f}  ({labels[np.argmax(magnitudes)]})')\n",
    "\n",
    "# Compare with demographic vectors\n",
    "try:\n",
    "    demo_vectors = torch.load(\n",
    "        os.path.join(VECTOR_DIR, f'gss_demographic_vectors_layer{REF_LAYER}.pt'),\n",
    "        map_location='cpu',\n",
    "        weights_only=True,\n",
    "    )\n",
    "    demo_mags = np.array([demo_vectors[lab]['magnitude'] for lab in sorted(demo_vectors.keys())])\n",
    "    print(f'\\nDemographic vector magnitudes (layer {REF_LAYER}):')\n",
    "    print(f'  Mean: {demo_mags.mean():.4f}, Std: {demo_mags.std():.4f}')\n",
    "    print(f'  Attitude vs Demographic ratio: {magnitudes.mean() / demo_mags.mean():.2f}x')\n",
    "except FileNotFoundError:\n",
    "    print('\\n(Demographic vectors not found for comparison)')\n",
    "\n",
    "# Top 10 highest-magnitude attitude positions\n",
    "print(f'\\nTop 10 highest-magnitude attitude positions:')\n",
    "sorted_idx = np.argsort(magnitudes)[::-1]\n",
    "for i in sorted_idx[:10]:\n",
    "    print(f'  {magnitudes[i]:.4f}  {labels[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attitude Space PCA\n",
    "\n",
    "Apply PCA to attitude vectors (with and without within-category centering) to discover\n",
    "the dominant axes of attitudinal variation in Llama-3's hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build unnormalized matrix: direction * magnitude\n",
    "X = np.array([\n",
    "    (vectors[lab]['vector'] * vectors[lab]['magnitude']).numpy()\n",
    "    for lab in labels\n",
    "])\n",
    "\n",
    "print(f'Attitude matrix: {X.shape}')\n",
    "\n",
    "# Original PCA (before centering)\n",
    "n_components = min(30, len(labels))\n",
    "pca_orig = PCA(n_components=n_components)\n",
    "X_pca_orig = pca_orig.fit_transform(X)\n",
    "\n",
    "print(f'PC1 variance: {pca_orig.explained_variance_ratio_[0]:.2%}')\n",
    "print(f'Top 5 PCs: {[f\"{v:.2%}\" for v in pca_orig.explained_variance_ratio_[:5]]}')\n",
    "print(f'Cumulative (10 PCs): {sum(pca_orig.explained_variance_ratio_[:10]):.2%}')\n",
    "\n",
    "# Color palette for 34 categories\n",
    "n_cats = len(unique_cats)\n",
    "tab20 = [get_cmap('tab20')(i / 20) for i in range(20)]\n",
    "tab20b = [get_cmap('tab20b')(i / 20) for i in range(20)]\n",
    "all_colors = tab20 + tab20b[:n_cats - 20] if n_cats > 20 else tab20[:n_cats]\n",
    "cat_to_color = {cat: all_colors[i] for i, cat in enumerate(unique_cats)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within-category centering: subtract category mean from each vector\n",
    "X_centered = np.copy(X)\n",
    "cat_means = {}\n",
    "\n",
    "for cat in unique_cats:\n",
    "    indices = [i for i, c in enumerate(categories) if c == cat]\n",
    "    cat_mean = X[indices].mean(axis=0)\n",
    "    cat_means[cat] = cat_mean\n",
    "    X_centered[indices] -= cat_mean\n",
    "\n",
    "# Verify centering\n",
    "print('Within-category centering verification:')\n",
    "for cat in unique_cats:\n",
    "    indices = [i for i, c in enumerate(categories) if c == cat]\n",
    "    mean_norm = np.linalg.norm(X_centered[indices].mean(axis=0))\n",
    "    n = len(indices)\n",
    "    print(f'  {cat:20s} ({n} positions): mean_norm = {mean_norm:.2e}')\n",
    "\n",
    "# Centered PCA\n",
    "pca_centered = PCA(n_components=n_components)\n",
    "X_pca_centered = pca_centered.fit_transform(X_centered)\n",
    "\n",
    "print(f'\\nCentered PCA:')\n",
    "print(f'  PC1 variance: {pca_centered.explained_variance_ratio_[0]:.2%}')\n",
    "print(f'  Top 5 PCs: {[f\"{v:.2%}\" for v in pca_centered.explained_variance_ratio_[:5]]}')\n",
    "print(f'  Cumulative (10 PCs): {sum(pca_centered.explained_variance_ratio_[:10]):.2%}')\n",
    "\n",
    "# Side-by-side scree plot: original vs centered\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].bar(range(1, 21), pca_centered.explained_variance_ratio_[:20],\n",
    "            color='steelblue', alpha=0.8)\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('Centered Attitude PCA \u2014 Scree Plot')\n",
    "axes[0].set_xticks(range(1, 21))\n",
    "\n",
    "cum_var = np.cumsum(pca_centered.explained_variance_ratio_[:20])\n",
    "axes[1].plot(range(1, 21), cum_var, 'bo-', linewidth=2, markersize=6)\n",
    "axes[1].axhline(0.8, color='red', linestyle='--', alpha=0.5, label='80%')\n",
    "axes[1].axhline(0.9, color='orange', linestyle='--', alpha=0.5, label='90%')\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].set_title('Cumulative Variance')\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(range(1, 21))\n",
    "\n",
    "axes[2].plot(range(1, 21), pca_orig.explained_variance_ratio_[:20],\n",
    "             'rs-', label='Original', linewidth=2)\n",
    "axes[2].plot(range(1, 21), pca_centered.explained_variance_ratio_[:20],\n",
    "             'bo-', label='Centered', linewidth=2)\n",
    "axes[2].set_xlabel('Principal Component')\n",
    "axes[2].set_ylabel('Explained Variance Ratio')\n",
    "axes[2].set_title('Original vs Centered')\n",
    "axes[2].legend()\n",
    "axes[2].set_xticks(range(1, 21))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centered = pd.DataFrame({\n",
    "    'PC1': X_pca_centered[:, 0],\n",
    "    'PC2': X_pca_centered[:, 1],\n",
    "    'PC3': X_pca_centered[:, 2],\n",
    "    'label': labels,\n",
    "    'category': categories,\n",
    "    'short_label': [lab.split('_', 1)[1][:35] for lab in labels],\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "for cat in unique_cats:\n",
    "    mask = df_centered['category'] == cat\n",
    "    ax.scatter(\n",
    "        df_centered.loc[mask, 'PC1'],\n",
    "        df_centered.loc[mask, 'PC2'],\n",
    "        label=cat, color=cat_to_color[cat],\n",
    "        s=80, alpha=0.8, edgecolors='white', linewidth=0.5,\n",
    "    )\n",
    "\n",
    "for _, row in df_centered.iterrows():\n",
    "    ax.annotate(\n",
    "        row['short_label'], (row['PC1'], row['PC2']),\n",
    "        fontsize=5, alpha=0.8, xytext=(3, 3), textcoords='offset points',\n",
    "    )\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.2)\n",
    "ax.axvline(0, color='black', linestyle='--', alpha=0.2)\n",
    "ax.set_xlabel(f'PC1 ({pca_centered.explained_variance_ratio_[0]:.1%})')\n",
    "ax.set_ylabel(f'PC2 ({pca_centered.explained_variance_ratio_[1]:.1%})')\n",
    "ax.set_title(f'Attitude Space \u2014 Centered PCA (Layer {REF_LAYER})')\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=7, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"=\" * 80}')\n",
    "print(f'CENTERED ATTITUDE PCA \u2014 PC POLES (Layer {REF_LAYER})')\n",
    "print(f'{\"=\" * 80}')\n",
    "\n",
    "for pc_idx in range(5):\n",
    "    pc_name = f'PC{pc_idx + 1}'\n",
    "    projections = X_pca_centered[:, pc_idx]\n",
    "    sorted_idx = np.argsort(projections)\n",
    "    var = pca_centered.explained_variance_ratio_[pc_idx]\n",
    "\n",
    "    print(f'\\n{pc_name} \u2014 Explained Variance: {var:.2%}')\n",
    "\n",
    "    print(f'  POSITIVE pole (top 10):')\n",
    "    for i in sorted_idx[-10:][::-1]:\n",
    "        print(f'    {projections[i]:+8.4f}  [{categories[i]:20s}]  {labels[i]}')\n",
    "\n",
    "    print(f'  NEGATIVE pole (bottom 10):')\n",
    "    for i in sorted_idx[:10]:\n",
    "        print(f'    {projections[i]:+8.4f}  [{categories[i]:20s}]  {labels[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Space Comparison: Attitude vs Demographic Vectors\n",
    "\n",
    "Compare Attitude Space with the Demographic Space from Phase 5.1:\n",
    "1. Cosine similarity heatmap between centered attitude and demographic vectors\n",
    "2. Joint PCA combining both sets of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demographic vectors\n",
    "demo_vectors = torch.load(\n",
    "    os.path.join(VECTOR_DIR, f'gss_demographic_vectors_layer{REF_LAYER}.pt'),\n",
    "    map_location='cpu',\n",
    "    weights_only=True,\n",
    ")\n",
    "\n",
    "demo_labels = sorted(demo_vectors.keys())\n",
    "demo_categories = [lab.split('_')[0] for lab in demo_labels]\n",
    "demo_unique_cats = sorted(set(demo_categories))\n",
    "\n",
    "# Build centered demographic matrix\n",
    "X_demo = np.array([\n",
    "    (demo_vectors[lab]['vector'] * demo_vectors[lab]['magnitude']).numpy()\n",
    "    for lab in demo_labels\n",
    "])\n",
    "\n",
    "X_demo_centered = np.copy(X_demo)\n",
    "for cat in demo_unique_cats:\n",
    "    indices = [i for i, c in enumerate(demo_categories) if c == cat]\n",
    "    cat_mean = X_demo[indices].mean(axis=0)\n",
    "    X_demo_centered[indices] -= cat_mean\n",
    "\n",
    "print(f'Demographic vectors: {len(demo_labels)} across {len(demo_unique_cats)} categories')\n",
    "print(f'Attitude vectors: {len(labels)} across {len(unique_cats)} categories')\n",
    "\n",
    "# Cosine similarity: centered attitudes x centered demographics\n",
    "cos_sim = cosine_similarity(X_centered, X_demo_centered)\n",
    "\n",
    "# Sort by attitude PC1 and demographic PC1\n",
    "demo_pca = PCA(n_components=10)\n",
    "X_demo_pca = demo_pca.fit_transform(X_demo_centered)\n",
    "\n",
    "att_order = np.argsort(X_pca_centered[:, 0])\n",
    "demo_order = np.argsort(X_demo_pca[:, 0])\n",
    "\n",
    "att_short = [labels[i].split('_', 1)[1][:30] for i in att_order]\n",
    "demo_short = [demo_labels[i].split('_', 1)[1][:25] for i in demo_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 14))\n",
    "sns.heatmap(\n",
    "    cos_sim[att_order][:, demo_order],\n",
    "    xticklabels=demo_short,\n",
    "    yticklabels=att_short,\n",
    "    cmap='RdBu_r',\n",
    "    center=0,\n",
    "    ax=ax,\n",
    "    cbar_kws={'label': 'Cosine Similarity'},\n",
    ")\n",
    "ax.set_xlabel('Demographic Vectors (sorted by demographic PC1)')\n",
    "ax.set_ylabel('Attitude Vectors (sorted by attitude PC1)')\n",
    "ax.set_title(f'Attitude x Demographic Cosine Similarity (Centered, Layer {REF_LAYER})')\n",
    "plt.xticks(fontsize=5, rotation=90)\n",
    "plt.yticks(fontsize=5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f'Cosine similarity matrix: {cos_sim.shape}')\n",
    "print(f'  Mean: {cos_sim.mean():.4f}')\n",
    "print(f'  Std:  {cos_sim.std():.4f}')\n",
    "print(f'  Range: [{cos_sim.min():.4f}, {cos_sim.max():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Stack centered attitude + centered demographic vectors\n",
    "X_joint = np.vstack([X_centered, X_demo_centered])\n",
    "joint_labels = labels + demo_labels\n",
    "joint_categories = categories + demo_categories\n",
    "joint_types = ['Attitude'] * len(labels) + ['Demographic'] * len(demo_labels)\n",
    "\n",
    "# Joint PCA\n",
    "pca_joint = PCA(n_components=min(30, len(joint_labels)))\n",
    "X_joint_pca = pca_joint.fit_transform(X_joint)\n",
    "\n",
    "print(f'Joint matrix: {X_joint.shape}')\n",
    "print(f'  Attitude vectors: {len(labels)}')\n",
    "print(f'  Demographic vectors: {len(demo_labels)}')\n",
    "print(f'  Joint PC1 variance: {pca_joint.explained_variance_ratio_[0]:.2%}')\n",
    "print(f'  Top 5 PCs: {[f\"{v:.2%}\" for v in pca_joint.explained_variance_ratio_[:5]]}')\n",
    "\n",
    "# Scatter: color by type\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "for i in range(len(joint_labels)):\n",
    "    if joint_types[i] == 'Attitude':\n",
    "        color, marker, alpha = 'tab:blue', 'o', 0.8\n",
    "    else:\n",
    "        color, marker, alpha = 'tab:orange', 's', 0.6\n",
    "    ax.scatter(\n",
    "        X_joint_pca[i, 0], X_joint_pca[i, 1],\n",
    "        color=color, marker=marker, s=50, alpha=alpha,\n",
    "        edgecolors='white', linewidth=0.3,\n",
    "    )\n",
    "\n",
    "# Annotate all points\n",
    "for i in range(len(joint_labels)):\n",
    "    short = joint_labels[i].split('_', 1)[1][:25]\n",
    "    ax.annotate(\n",
    "        short, (X_joint_pca[i, 0], X_joint_pca[i, 1]),\n",
    "        fontsize=4, alpha=0.6, xytext=(2, 2), textcoords='offset points',\n",
    "    )\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.2)\n",
    "ax.axvline(0, color='black', linestyle='--', alpha=0.2)\n",
    "ax.set_xlabel(f'PC1 ({pca_joint.explained_variance_ratio_[0]:.1%})')\n",
    "ax.set_ylabel(f'PC2 ({pca_joint.explained_variance_ratio_[1]:.1%})')\n",
    "ax.set_title(f'Joint Attitude + Demographic PCA (Centered, Layer {REF_LAYER})')\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='tab:blue',\n",
    "           markersize=10, label='Attitude'),\n",
    "    Line2D([0], [0], marker='s', color='w', markerfacecolor='tab:orange',\n",
    "           markersize=10, label='Demographic'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_layers = [5, 9, 13, 17, 20]\n",
    "layer_results = {}\n",
    "\n",
    "for layer in comparison_layers:\n",
    "    vecs = torch.load(\n",
    "        os.path.join(VECTOR_DIR, f'gss_attitude_vectors_layer{layer}.pt'),\n",
    "        map_location='cpu',\n",
    "        weights_only=True,\n",
    "    )\n",
    "\n",
    "    layer_labels = sorted(vecs.keys())\n",
    "    layer_cats = [lab.split('_')[0] for lab in layer_labels]\n",
    "    layer_unique_cats = sorted(set(layer_cats))\n",
    "\n",
    "    layer_X = np.array([\n",
    "        (vecs[lab]['vector'] * vecs[lab]['magnitude']).numpy()\n",
    "        for lab in layer_labels\n",
    "    ])\n",
    "\n",
    "    # Within-category centering\n",
    "    layer_X_c = np.copy(layer_X)\n",
    "    for cat in layer_unique_cats:\n",
    "        indices = [i for i, c in enumerate(layer_cats) if c == cat]\n",
    "        cat_mean = layer_X[indices].mean(axis=0)\n",
    "        layer_X_c[indices] -= cat_mean\n",
    "\n",
    "    pca_c = PCA(n_components=min(20, len(layer_labels)))\n",
    "    X_pca_c = pca_c.fit_transform(layer_X_c)\n",
    "\n",
    "    layer_results[layer] = {\n",
    "        'labels': layer_labels,\n",
    "        'categories': layer_cats,\n",
    "        'X_pca': X_pca_c,\n",
    "        'pca': pca_c,\n",
    "        'explained_variance': pca_c.explained_variance_ratio_,\n",
    "    }\n",
    "\n",
    "    print(f'Layer {layer:2d}: PC1={pca_c.explained_variance_ratio_[0]:.2%}, '\n",
    "          f'PC2={pca_c.explained_variance_ratio_[1]:.2%}, '\n",
    "          f'PC3={pca_c.explained_variance_ratio_[2]:.2%}')\n",
    "\n",
    "# Variance comparison plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for layer in comparison_layers:\n",
    "    res = layer_results[layer]\n",
    "    axes[0].plot(\n",
    "        range(1, 11), res['explained_variance'][:10],\n",
    "        'o-', label=f'Layer {layer}', linewidth=2, markersize=5,\n",
    "    )\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('Centered Attitude PCA \u2014 Variance by Layer')\n",
    "axes[0].legend()\n",
    "axes[0].set_xticks(range(1, 11))\n",
    "\n",
    "# PC1 variance across layers\n",
    "pc1_vars = [layer_results[l]['explained_variance'][0] for l in comparison_layers]\n",
    "axes[1].bar(range(len(comparison_layers)), pc1_vars, color='steelblue', alpha=0.8)\n",
    "axes[1].set_xticks(range(len(comparison_layers)))\n",
    "axes[1].set_xticklabels([f'Layer {l}' for l in comparison_layers])\n",
    "axes[1].set_ylabel('PC1 Explained Variance')\n",
    "axes[1].set_title('PC1 Variance Across Layers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PC1 pole stability across layers\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "print('PC1 POLES ACROSS LAYERS')\n",
    "print(f'{\"=\" * 60}')\n",
    "\n",
    "for layer in comparison_layers:\n",
    "    res = layer_results[layer]\n",
    "    projections = res['X_pca'][:, 0]\n",
    "    sorted_idx = np.argsort(projections)\n",
    "\n",
    "    print(f'\\nLayer {layer} (PC1 = {res[\"explained_variance\"][0]:.2%}):')\n",
    "    top5 = ', '.join(\n",
    "        res['labels'][i].split('_', 1)[1][:30] for i in sorted_idx[-5:][::-1]\n",
    "    )\n",
    "    bot5 = ', '.join(\n",
    "        res['labels'][i].split('_', 1)[1][:30] for i in sorted_idx[:5]\n",
    "    )\n",
    "    print(f'  + pole: {top5}')\n",
    "    print(f'  - pole: {bot5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Interpretation\n",
    "\n",
    "### Attitude Space\n",
    "- **~96 attitude positions** across **34 GSS social-issue variables** extracted from Llama-3 layers 5-20\n",
    "- Shared baseline optimization: all positions use the same \"person\" baseline, computed once per layer\n",
    "- Within-category centering removes the shared \"attitude-ness\" direction per variable\n",
    "\n",
    "### Key Questions\n",
    "1. **Is attitude PC1 a liberal-conservative axis?** Since attitudes are inherently political (unlike demographics), we expect a clearer partisan structure in attitude PC1.\n",
    "2. **Do attitude and demographic vectors intermingle in joint PCA?** If they share the same representational space, the model encodes attitudes and demographics along similar directions.\n",
    "3. **Which layer shows the strongest attitude structure?** Compare with demographic results from Phase 5.1.\n",
    "\n",
    "### Next Steps\n",
    "- Project demographic vectors onto attitude PCs (and vice versa) for cross-space alignment\n",
    "- Use attitude vectors for steering experiments on policy questions\n",
    "- Combine attitude + demographic vectors for composite persona steering"
   ]
  }
 ]
}