{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/yilmajung/belief_and_llms_v0/blob/main/5_demographic_space_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Demographic Space Mapping via PCA\n",
    "\n",
    "This notebook applies PCA to the 120 extracted demographic vectors to discover a low-dimensional\n",
    "\"Demographic Space\" — analogous to the \"Assistant Axis\" from Lu et al. (2026).\n",
    "\n",
    "**Goals:**\n",
    "1. Identify interpretable principal components (PC1, PC2, PC3)\n",
    "2. Visualize the demographic landscape in 2D/3D\n",
    "3. Compare PCA structure with GSS phi-coefficient correlations\n",
    "4. Analyze how demographic structure varies across layers\n",
    "\n",
    "**Input:** `vectors/gss_demographic_vectors_layer{N}.pt` (120 vectors × 4096 dims per layer)\n",
    "\n",
    "**No GPU required** — PCA on a 120 × 4096 matrix is CPU-only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib.cm import get_cmap\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Colab) or use local path\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    BASE_DIR = \"/content/drive/MyDrive/belief_and_llms_v0\"\n",
    "except ImportError:\n",
    "    BASE_DIR = \".\"\n",
    "\n",
    "VECTOR_DIR = os.path.join(BASE_DIR, \"vectors\")\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "# Reference layer: 13 (peak delta magnitude from Phase 3 analysis)\n",
    "REF_LAYER = 13\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Vector directory: {VECTOR_DIR}\")\n",
    "print(f\"Reference layer: {REF_LAYER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectors for the reference layer\n",
    "vectors = torch.load(\n",
    "    os.path.join(VECTOR_DIR, f\"gss_demographic_vectors_layer{REF_LAYER}.pt\"),\n",
    "    map_location=\"cpu\",\n",
    "    weights_only=True,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(vectors)} demographic vectors from layer {REF_LAYER}\")\n",
    "print(f\"Vector dimension: {vectors[list(vectors.keys())[0]]['vector'].shape[0]}\")\n",
    "print(f\"\\nCategories: {sorted(set(k.split('_')[0] for k in vectors.keys()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vector Matrix\n",
    "\n",
    "We use **unnormalized vectors** (direction × magnitude) for PCA, since magnitude encodes how strongly the model differentiates each demographic. This follows the approach in \"The Assistant Axis\" (Lu et al., 2026)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(vectors.keys())\n",
    "categories = [label.split('_')[0] for label in labels]\n",
    "\n",
    "# Reconstruct raw (unnormalized) vectors: direction * magnitude\n",
    "raw_matrix = []\n",
    "for label in labels:\n",
    "    v = vectors[label]['vector'] * vectors[label]['magnitude']\n",
    "    raw_matrix.append(v.numpy())\n",
    "X = np.array(raw_matrix)  # Shape: (120, 4096)\n",
    "\n",
    "# Also build normalized-only matrix for comparison\n",
    "norm_matrix = np.array([vectors[label]['vector'].numpy() for label in labels])\n",
    "\n",
    "print(f\"Unnormalized matrix shape: {X.shape}\")\n",
    "print(f\"Normalized matrix shape: {norm_matrix.shape}\")\n",
    "\n",
    "# Show magnitude distribution\n",
    "magnitudes = np.array([vectors[label]['magnitude'] for label in labels])\n",
    "print(f\"\\nMagnitude stats: min={magnitudes.min():.4f}, max={magnitudes.max():.4f}, \"\n",
    "      f\"mean={magnitudes.mean():.4f}, std={magnitudes.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA: Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = min(30, len(labels))\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Also run PCA on normalized vectors for comparison\n",
    "pca_norm = PCA(n_components=n_components)\n",
    "X_pca_norm = pca_norm.fit_transform(norm_matrix)\n",
    "\n",
    "# Scree plot and cumulative variance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Scree plot (unnormalized)\n",
    "axes[0].bar(range(1, 21), pca.explained_variance_ratio_[:20], color='steelblue', alpha=0.8)\n",
    "axes[0].set_xlabel('Principal Component', fontsize=12)\n",
    "axes[0].set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "axes[0].set_title('Scree Plot (unnormalized vectors)', fontsize=13)\n",
    "axes[0].set_xticks(range(1, 21))\n",
    "\n",
    "# Cumulative (unnormalized)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_[:20])\n",
    "axes[1].plot(range(1, 21), cum_var, 'bo-', linewidth=2, markersize=6)\n",
    "axes[1].axhline(0.8, color='red', linestyle='--', alpha=0.5, label='80%')\n",
    "axes[1].axhline(0.9, color='orange', linestyle='--', alpha=0.5, label='90%')\n",
    "axes[1].set_xlabel('Number of Components', fontsize=12)\n",
    "axes[1].set_ylabel('Cumulative Explained Variance', fontsize=12)\n",
    "axes[1].set_title('Cumulative Variance (unnormalized)', fontsize=13)\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(range(1, 21))\n",
    "\n",
    "# Comparison: unnormalized vs normalized\n",
    "axes[2].plot(range(1, 21), pca.explained_variance_ratio_[:20], 'bo-', label='Unnormalized', linewidth=2)\n",
    "axes[2].plot(range(1, 21), pca_norm.explained_variance_ratio_[:20], 'rs-', label='Normalized', linewidth=2)\n",
    "axes[2].set_xlabel('Principal Component', fontsize=12)\n",
    "axes[2].set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "axes[2].set_title('Unnormalized vs Normalized', fontsize=13)\n",
    "axes[2].legend()\n",
    "axes[2].set_xticks(range(1, 21))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 10 PCs explained variance (unnormalized):\")\n",
    "for i in range(10):\n",
    "    print(f\"  PC{i+1}: {pca.explained_variance_ratio_[i]:.4f} \"\n",
    "          f\"(cumulative: {sum(pca.explained_variance_ratio_[:i+1]):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC1 vs PC2: Demographic Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build PCA dataframe\n",
    "df_pca = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'PC3': X_pca[:, 2],\n",
    "    'label': labels,\n",
    "    'category': categories,\n",
    "    'short_label': [label.split('_', 1)[1][:30] for label in labels],\n",
    "    'magnitude': magnitudes,\n",
    "})\n",
    "\n",
    "# Color palette for ~25 categories\n",
    "unique_cats = sorted(df_pca['category'].unique())\n",
    "n_cats = len(unique_cats)\n",
    "tab20 = [get_cmap('tab20')(i / 20) for i in range(20)]\n",
    "tab20b = [get_cmap('tab20b')(i / 20) for i in range(20)]\n",
    "all_colors = tab20 + tab20b[:n_cats - 20] if n_cats > 20 else tab20[:n_cats]\n",
    "cat_to_color = {cat: all_colors[i] for i, cat in enumerate(unique_cats)}\n",
    "\n",
    "# PC1 vs PC2 scatter\n",
    "fig, ax = plt.subplots(figsize=(18, 14))\n",
    "\n",
    "for cat in unique_cats:\n",
    "    mask = df_pca['category'] == cat\n",
    "    ax.scatter(\n",
    "        df_pca.loc[mask, 'PC1'], df_pca.loc[mask, 'PC2'],\n",
    "        label=cat, color=cat_to_color[cat], s=80, alpha=0.8,\n",
    "        edgecolors='white', linewidth=0.5,\n",
    "    )\n",
    "\n",
    "# Annotate all points\n",
    "for _, row in df_pca.iterrows():\n",
    "    ax.annotate(\n",
    "        row['short_label'], (row['PC1'], row['PC2']),\n",
    "        fontsize=5.5, alpha=0.8,\n",
    "        xytext=(3, 3), textcoords='offset points',\n",
    "    )\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.2)\n",
    "ax.axvline(0, color='black', linestyle='--', alpha=0.2)\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=14)\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=14)\n",
    "ax.set_title(f'Demographic Space: PC1 vs PC2 (Layer {REF_LAYER})', fontsize=16)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC1 vs PC3 and PC2 vs PC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 9))\n",
    "\n",
    "for ax, (pcx, pcy), title in zip(\n",
    "    axes,\n",
    "    [('PC1', 'PC3'), ('PC2', 'PC3')],\n",
    "    ['PC1 vs PC3', 'PC2 vs PC3'],\n",
    "):\n",
    "    for cat in unique_cats:\n",
    "        mask = df_pca['category'] == cat\n",
    "        ax.scatter(\n",
    "            df_pca.loc[mask, pcx], df_pca.loc[mask, pcy],\n",
    "            label=cat, color=cat_to_color[cat], s=60, alpha=0.8,\n",
    "            edgecolors='white', linewidth=0.5,\n",
    "        )\n",
    "\n",
    "    for _, row in df_pca.iterrows():\n",
    "        ax.annotate(\n",
    "            row['short_label'], (row[pcx], row[pcy]),\n",
    "            fontsize=5, alpha=0.7,\n",
    "            xytext=(3, 3), textcoords='offset points',\n",
    "        )\n",
    "\n",
    "    pc_x_idx = int(pcx[2]) - 1\n",
    "    pc_y_idx = int(pcy[2]) - 1\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=0.2)\n",
    "    ax.axvline(0, color='black', linestyle='--', alpha=0.2)\n",
    "    ax.set_xlabel(f'{pcx} ({pca.explained_variance_ratio_[pc_x_idx]:.1%})', fontsize=12)\n",
    "    ax.set_ylabel(f'{pcy} ({pca.explained_variance_ratio_[pc_y_idx]:.1%})', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "\n",
    "axes[1].legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=7, ncol=2)\n",
    "plt.suptitle(f'Demographic Space: Additional PC Projections (Layer {REF_LAYER})', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Interpretation: Top/Bottom Demographics on Each PC\n",
    "\n",
    "For each PC, the \"poles\" (highest/lowest projections) reveal what that axis represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pc_idx in range(5):\n",
    "    pc_name = f'PC{pc_idx + 1}'\n",
    "    projections = X_pca[:, pc_idx]\n",
    "    sorted_idx = np.argsort(projections)\n",
    "\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"{pc_name} — Explained Variance: {pca.explained_variance_ratio_[pc_idx]:.2%}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    print(f\"\\n  POSITIVE pole (top 10):\")\n",
    "    for i in sorted_idx[-10:][::-1]:\n",
    "        print(f\"    {projections[i]:+8.4f}  [{categories[i]:12s}]  {labels[i]}\")\n",
    "\n",
    "    print(f\"\\n  NEGATIVE pole (bottom 10):\")\n",
    "    for i in sorted_idx[:10]:\n",
    "        print(f\"    {projections[i]:+8.4f}  [{categories[i]:12s}]  {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal bar chart of PC1 projections for all 120 demographics\n",
    "sorted_idx = np.argsort(X_pca[:, 0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 30))\n",
    "y_pos = range(len(sorted_idx))\n",
    "bar_colors = [cat_to_color[categories[i]] for i in sorted_idx]\n",
    "\n",
    "ax.barh(y_pos, X_pca[sorted_idx, 0], color=bar_colors, height=0.8, alpha=0.85)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels([labels[i] for i in sorted_idx], fontsize=6)\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.set_xlabel('PC1 Projection', fontsize=12)\n",
    "ax.set_title(f'All 120 Demographics Ranked by PC1 (Layer {REF_LAYER})', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing: What Do the PCs Represent?\n",
    "\n",
    "Based on the poles above, we test specific hypotheses:\n",
    "\n",
    "**PC1 hypothesis — Liberal-Conservative axis:**\n",
    "- Positive pole: Strong Republican, Conservative, Gun Owner, Believes in God firmly\n",
    "- Negative pole: Strong Democrat, Liberal, Non-believer, No gun\n",
    "\n",
    "**PC2 hypothesis — Socioeconomic/Education axis:**\n",
    "- One pole: Graduate degree, Upper class, High income, Professional occupations\n",
    "- Other pole: Less than high school, Lower class, Low income, Service/production jobs\n",
    "\n",
    "**PC3 hypothesis — Age/Generation or Urban/Rural axis:**\n",
    "- Needs to be determined from the data above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PC1 as Liberal-Conservative: compute average PC1 for politically-relevant groups\n",
    "political_groups = {\n",
    "    'Liberal cluster': [\n",
    "        'PartyID_Strong Democrat',\n",
    "        'PolViews_person with a liberal political view',\n",
    "        'PolViews_person with an extremely liberal political view',\n",
    "    ],\n",
    "    'Conservative cluster': [\n",
    "        'PartyID_Strong Republican',\n",
    "        'PolViews_person with a conservative political view',\n",
    "        'PolViews_person with an extremely conservative political view',\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"PC1 projections for politically-relevant groups:\")\n",
    "print(\"=\" * 60)\n",
    "for group_name, group_labels in political_groups.items():\n",
    "    print(f\"\\n{group_name}:\")\n",
    "    pc1_values = []\n",
    "    for lab in group_labels:\n",
    "        if lab in labels:\n",
    "            idx = labels.index(lab)\n",
    "            val = X_pca[idx, 0]\n",
    "            pc1_values.append(val)\n",
    "            print(f\"  {val:+8.4f}  {lab}\")\n",
    "    if pc1_values:\n",
    "        print(f\"  {'Mean':>8s}: {np.mean(pc1_values):+.4f}\")\n",
    "\n",
    "# Also check culture war demographics\n",
    "print(\"\\nCulture war demographics on PC1:\")\n",
    "print(\"=\" * 60)\n",
    "culture_labels = [\n",
    "    'OwnGun_gun owner', 'OwnGun_person who does not own a gun',\n",
    "    'God_person who firmly believes in God', 'God_person who does not believe in God',\n",
    "    'Urbanity_person living in a rural area', 'Urbanity_person living in a central city',\n",
    "]\n",
    "for lab in culture_labels:\n",
    "    if lab in labels:\n",
    "        idx = labels.index(lab)\n",
    "        print(f\"  {X_pca[idx, 0]:+8.4f}  {lab}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Heatmap\n",
    "\n",
    "120 × 120 cosine similarity matrix between all demographic vectors, ordered by PC1 projection to reveal cluster structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity in full 4096-dim space\n",
    "cos_sim = cosine_similarity(X)\n",
    "\n",
    "# Reorder by PC1 projection\n",
    "order = np.argsort(X_pca[:, 0])\n",
    "cos_sim_ordered = cos_sim[order][:, order]\n",
    "labels_ordered = [labels[i] for i in order]\n",
    "short_labels_ordered = [lab.split('_', 1)[1][:25] for lab in labels_ordered]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 18))\n",
    "im = ax.imshow(cos_sim_ordered, cmap='RdBu_r', vmin=-1, vmax=1, aspect='equal')\n",
    "ax.set_xticks(range(len(labels_ordered)))\n",
    "ax.set_yticks(range(len(labels_ordered)))\n",
    "ax.set_xticklabels(short_labels_ordered, rotation=90, fontsize=4)\n",
    "ax.set_yticklabels(short_labels_ordered, fontsize=4)\n",
    "ax.set_title(f'Cosine Similarity Between 120 Demographic Vectors (ordered by PC1, Layer {REF_LAYER})',\n",
    "             fontsize=14)\n",
    "plt.colorbar(im, ax=ax, shrink=0.8, label='Cosine Similarity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSimilarity stats: min={cos_sim.min():.4f}, max (off-diag)={np.fill_diagonal(cos_sim.copy(), 0) or cos_sim.max():.4f}, mean={cos_sim[np.triu_indices_from(cos_sim, k=1)].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare PCA Structure with GSS Phi-Coefficient Correlations\n",
    "\n",
    "Do demographics that are close in the model's vector space also have high phi-coefficient correlation in real GSS survey data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from GSS correlation pair names to extraction dataset labels\n",
    "# The correlation CSV uses GSS-internal names; extraction datasets use descriptive labels\n",
    "GSS_TO_VECTOR = {\n",
    "    # Race\n",
    "    'race_Black': 'Race_Black person',\n",
    "    'race_White': 'Race_White person',\n",
    "    'race_Other': 'Race_person of different race than Black or White',\n",
    "    # PartyID\n",
    "    'partyid_Strong democrat': 'PartyID_Strong Democrat',\n",
    "    'partyid_Strong republican': 'PartyID_Strong Republican',\n",
    "    'partyid_Not very strong democrat': 'PartyID_Democrat',\n",
    "    'partyid_Not very strong republican': 'PartyID_Republican',\n",
    "    'partyid_Independent, close to democrat': 'PartyID_Independent leaning Democrat',\n",
    "    'partyid_Independent, close to republican': 'PartyID_Independent leaning Republican',\n",
    "    'partyid_Independent (neither, no response)': 'PartyID_Political Independent',\n",
    "    'partyid_Other party': 'PartyID_Other',\n",
    "    # Sex\n",
    "    'sex_MALE': 'Sex_man',\n",
    "    'sex_FEMALE': 'Sex_woman',\n",
    "    # Degree\n",
    "    'degree_Less than high school': 'Degree_person with less than high school education',\n",
    "    'degree_High school': 'Degree_high school graduate',\n",
    "    'degree_Associate/junior college': 'Degree_person with some college education',\n",
    "    \"degree_Bachelor's\": 'Degree_person with a bachelor\\'s degree',\n",
    "    'degree_Graduate': 'Degree_person with a graduate degree',\n",
    "    # Religion\n",
    "    'relig_Catholic': 'Religion_Catholic',\n",
    "    'relig_Protestant': 'Religion_Protestant',\n",
    "    'relig_Buddhism': 'Religion_Buddhist',\n",
    "    'relig_Jewish': 'Religion_Jewish person',\n",
    "    'relig_Muslim/Islam': 'Religion_Muslim',\n",
    "    'relig_Hinduism': 'Religion_Hindu',\n",
    "    'relig_Other': 'Religion_person of other religion',\n",
    "    # PolViews\n",
    "    'polviews_Extremely liberal': 'PolViews_person with an extremely liberal political view',\n",
    "    'polviews_Liberal': 'PolViews_person with a liberal political view',\n",
    "    'polviews_Slightly liberal': 'PolViews_person with a slightly liberal political view',\n",
    "    'polviews_Moderate, middle of the road': 'PolViews_person with a neutral political view',\n",
    "    'polviews_Slightly conservative': 'PolViews_person with a slightly conservative political view',\n",
    "    'polviews_Conservative': 'PolViews_person with a conservative political view',\n",
    "    'polviews_Extremely conservative': 'PolViews_person with an extremely conservative political view',\n",
    "    # Generation\n",
    "    'generation_Generation Z': 'Generation_person from Generation Z',\n",
    "    'generation_Millennial': 'Generation_Millennial',\n",
    "    'generation_Generation X': 'Generation_person from Generation X',\n",
    "    'generation_Baby Boomer': 'Generation_Baby Boomer',\n",
    "    'generation_Silent Generation': 'Generation_person from the Silent Generation',\n",
    "    # Marital\n",
    "    'marital_Married': 'Marital_married person',\n",
    "    'marital_Divorced': 'Marital_divorced person',\n",
    "    'marital_Widowed': 'Marital_widowed person',\n",
    "    'marital_Separated': 'Marital_separated person',\n",
    "    'marital_Never married': 'Marital_person who has never been married',\n",
    "    # Age\n",
    "    'age_group_Youth (15-24)': 'Age_young person aged 15 to 24',\n",
    "    'age_group_Young Adult (25-39)': 'Age_young adult aged 25 to 39',\n",
    "    'age_group_Middle Adult (40-64)': 'Age_middle-aged adult aged 40 to 64',\n",
    "    'age_group_Elderly (65+)': 'Age_elderly person aged 65 or older',\n",
    "    # Children\n",
    "    'childs_group_No children': 'Children_person with no children',\n",
    "    'childs_group_1-2 children': 'Children_person with one or two children',\n",
    "    'childs_group_3 or more children': 'Children_person with three or more children',\n",
    "    # Immigration\n",
    "    'immig_gen_1st generation immigrant': 'ImmigGen_first-generation immigrant to the United States',\n",
    "    'immig_gen_2nd generation immigrant': 'ImmigGen_second-generation immigrant in the United States',\n",
    "    'immig_gen_3rd+ generation American': 'ImmigGen_third-generation or later American',\n",
    "    # Region (grew up)\n",
    "    'reg16_Northeast': 'Region16_person who grew up in the Northeast',\n",
    "    'reg16_Midwest': 'Region16_person who grew up in the Midwest',\n",
    "    'reg16_South': 'Region16_person who grew up in the South',\n",
    "    'reg16_West': 'Region16_person who grew up in the West',\n",
    "    'reg16_Foreign': 'Region16_person who grew up in a foreign country',\n",
    "    # Family income\n",
    "    'income_group_Income under $10k': 'FamilyIncome_person with a family income under $10,000',\n",
    "    'income_group_Income $10k-$25k': 'FamilyIncome_person with a family income between $10,000 and $25,000',\n",
    "    'income_group_Income $25k or more': 'FamilyIncome_person with a family income of $25,000 or more',\n",
    "    # Region (current)\n",
    "    'region_Northeast': 'Region_person living in the Northeast',\n",
    "    'region_Midwest': 'Region_person living in the Midwest',\n",
    "    'region_South': 'Region_person living in the South',\n",
    "    'region_West': 'Region_person living in the West',\n",
    "    # Urbanity (srcbelt)\n",
    "    'srcbelt_group_Central city': 'Urbanity_person living in a central city',\n",
    "    'srcbelt_group_Suburban': 'Urbanity_person living in the suburbs',\n",
    "    'srcbelt_group_Other urban': 'Urbanity_person living in a small city or town',\n",
    "    'srcbelt_group_Rural': 'Urbanity_person living in a rural area',\n",
    "    # Happiness\n",
    "    'happy_Very happy': 'Happy_very happy person',\n",
    "    'happy_Pretty happy': 'Happy_fairly happy person',\n",
    "    'happy_Not too happy': 'Happy_unhappy person',\n",
    "    # Health\n",
    "    'health_Excellent': 'Health_person in excellent health',\n",
    "    'health_Good': 'Health_person in good health',\n",
    "    'health_Fair': 'Health_person in fair health',\n",
    "    'health_Poor': 'Health_person in poor health',\n",
    "    # Life excitement\n",
    "    'life_Exciting': 'Life_person who finds life exciting',\n",
    "    'life_Routine': 'Life_person who finds life routine',\n",
    "    'life_Dull': 'Life_person who finds life dull',\n",
    "    # Job satisfaction\n",
    "    'satjob_group_Very satisfied': 'SatJob_person very satisfied with their job',\n",
    "    'satjob_group_Moderately satisfied': 'SatJob_person moderately satisfied with their job',\n",
    "    'satjob_group_Dissatisfied': 'SatJob_person dissatisfied with their job',\n",
    "    # Social class\n",
    "    'class__Lower class': 'Class_lower class person',\n",
    "    'class__Working class': 'Class_working class person',\n",
    "    'class__Middle class': 'Class_middle class person',\n",
    "    'class__Upper class': 'Class_upper class person',\n",
    "    # Financial satisfaction\n",
    "    'satfin_Pretty well satisfied': 'SatFin_person satisfied with their financial situation',\n",
    "    'satfin_More or less satisfied': 'SatFin_person somewhat satisfied with their financial situation',\n",
    "    'satfin_Not satisfied at all': 'SatFin_person not satisfied with their financial situation',\n",
    "    # Gun ownership\n",
    "    'owngun_YES': 'OwnGun_gun owner',\n",
    "    'owngun_NO': 'OwnGun_person who does not own a gun',\n",
    "    # Belief in God\n",
    "    'god_No doubts': 'God_person who firmly believes in God',\n",
    "    'god_Believe with doubts': 'God_person who believes in God but with some doubts',\n",
    "    'god_Believe sometimes': 'God_person who sometimes believes in God',\n",
    "    \"god_Don't know, no way to find out\": 'God_agnostic person',\n",
    "    'god_Higher power': 'God_person who believes in a higher power but not a personal God',\n",
    "    \"god_Don't believe\": 'God_person who does not believe in God',\n",
    "    # Occupation\n",
    "    'occ_group_Service': 'Occupation_person working in a service occupation',\n",
    "    'occ_group_Natural Resources, Construction, and Maintenance': 'Occupation_person working in construction, maintenance, or natural resources',\n",
    "    'occ_group_Office and Administrative Support': 'Occupation_person working in an office or administrative support role',\n",
    "    'occ_group_Management, Business, and Financial': 'Occupation_person working in management, business, or finance',\n",
    "    'occ_group_Education, Legal, Community Service, Arts, and Media': 'Occupation_person working in education, law, community service, arts, or media',\n",
    "    'occ_group_Computer, Engineering, and Science': 'Occupation_person working in computer science, engineering, or science',\n",
    "    'occ_group_Military': 'Occupation_person serving in the military',\n",
    "    'occ_group_Production, Transportation, and Material Moving': 'Occupation_person working in production or transportation',\n",
    "    'occ_group_Sales and Related': 'Occupation_person working in sales',\n",
    "    'occ_group_Healthcare Practitioners and Technical': 'Occupation_healthcare practitioner',\n",
    "    # Industry\n",
    "    'indus_group_Health Care and Social Assistance': 'Industry_person working in healthcare or social assistance',\n",
    "    'indus_group_Wholesale Trade': 'Industry_person working in wholesale trade',\n",
    "    'indus_group_Manufacturing': 'Industry_person working in manufacturing',\n",
    "    'indus_group_Construction': 'Industry_person working in the construction industry',\n",
    "    'indus_group_Finance and Insurance, and Real Estate': 'Industry_person working in finance, insurance, or real estate',\n",
    "    'indus_group_Arts, Entertainment, Recreation, and Accommodation and Food Services': 'Industry_person working in arts, entertainment, or food services',\n",
    "    'indus_group_Information': 'Industry_person working in the information industry',\n",
    "    'indus_group_Educational Services': 'Industry_person working in educational services',\n",
    "    'indus_group_Public Administration': 'Industry_person working in public administration',\n",
    "    'indus_group_Professional, Scientific, Management, and Administrative Services': 'Industry_person working in professional or scientific services',\n",
    "    'indus_group_Transportation and Warehousing, and Utilities': 'Industry_person working in transportation or utilities',\n",
    "    'indus_group_Retail Trade': 'Industry_person working in retail',\n",
    "    'indus_group_Other Services (Except Public Administration)': 'Industry_person working in other services',\n",
    "    'indus_group_Agriculture, Forestry, Fishing and Hunting, and Mining': 'Industry_person working in agriculture or mining',\n",
    "}\n",
    "\n",
    "# Verify mapping coverage\n",
    "mapped_vectors = set(GSS_TO_VECTOR.values())\n",
    "available_vectors = set(labels)\n",
    "missing = mapped_vectors - available_vectors\n",
    "unmapped = available_vectors - mapped_vectors\n",
    "\n",
    "print(f\"Mapping entries: {len(GSS_TO_VECTOR)}\")\n",
    "print(f\"Vectors with GSS mapping: {len(mapped_vectors & available_vectors)}\")\n",
    "if missing:\n",
    "    print(f\"WARNING: Mapped but not in vectors: {missing}\")\n",
    "if unmapped:\n",
    "    print(f\"Vectors without GSS mapping: {unmapped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GSS phi-coefficient correlations\n",
    "corr_df = pd.read_csv(os.path.join(DATA_DIR, \"gss_correlation_pairs.csv\"))\n",
    "print(f\"Loaded {len(corr_df)} correlation pairs\")\n",
    "\n",
    "# For each pair, compute cosine similarity between vectors\n",
    "comparison_data = []\n",
    "label_to_idx = {lab: i for i, lab in enumerate(labels)}\n",
    "\n",
    "for _, row in corr_df.iterrows():\n",
    "    var1, var2, phi = row['Var1'], row['Var2'], row['Correlation']\n",
    "\n",
    "    vec_label1 = GSS_TO_VECTOR.get(var1)\n",
    "    vec_label2 = GSS_TO_VECTOR.get(var2)\n",
    "\n",
    "    if vec_label1 and vec_label2 and vec_label1 in label_to_idx and vec_label2 in label_to_idx:\n",
    "        idx1 = label_to_idx[vec_label1]\n",
    "        idx2 = label_to_idx[vec_label2]\n",
    "        vec_cos = cos_sim[idx1, idx2]\n",
    "        comparison_data.append({\n",
    "            'gss_var1': var1, 'gss_var2': var2,\n",
    "            'vec_label1': vec_label1, 'vec_label2': vec_label2,\n",
    "            'phi_coefficient': phi,\n",
    "            'cosine_similarity': vec_cos,\n",
    "        })\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_data)\n",
    "print(f\"Matched {len(comp_df)} out of {len(corr_df)} correlation pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: GSS phi-coefficient vs vector cosine similarity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Full scatter\n",
    "ax = axes[0]\n",
    "ax.scatter(comp_df['phi_coefficient'], comp_df['cosine_similarity'],\n",
    "           alpha=0.3, s=20, color='steelblue')\n",
    "\n",
    "# Fit line\n",
    "z = np.polyfit(comp_df['phi_coefficient'], comp_df['cosine_similarity'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_fit = np.linspace(comp_df['phi_coefficient'].min(), comp_df['phi_coefficient'].max(), 100)\n",
    "ax.plot(x_fit, p(x_fit), 'r-', linewidth=2, alpha=0.7)\n",
    "\n",
    "corr = comp_df['phi_coefficient'].corr(comp_df['cosine_similarity'])\n",
    "ax.set_xlabel('GSS Phi-Coefficient', fontsize=12)\n",
    "ax.set_ylabel('Vector Cosine Similarity', fontsize=12)\n",
    "ax.set_title(f'GSS Correlation vs Vector Similarity (r={corr:.3f})', fontsize=13)\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.3)\n",
    "ax.axvline(0, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Highlight extreme pairs\n",
    "ax2 = axes[1]\n",
    "top_pairs = comp_df.nlargest(20, 'phi_coefficient')\n",
    "bottom_pairs = comp_df.nsmallest(20, 'phi_coefficient')\n",
    "extreme = pd.concat([top_pairs, bottom_pairs])\n",
    "\n",
    "colors = ['green' if r['phi_coefficient'] > 0 else 'red' for _, r in extreme.iterrows()]\n",
    "ax2.scatter(extreme['phi_coefficient'], extreme['cosine_similarity'],\n",
    "            alpha=0.6, s=40, c=colors)\n",
    "\n",
    "for _, r in extreme.iterrows():\n",
    "    short1 = r['vec_label1'].split('_', 1)[1][:15]\n",
    "    short2 = r['vec_label2'].split('_', 1)[1][:15]\n",
    "    ax2.annotate(f\"{short1}\\n  vs {short2}\",\n",
    "                 (r['phi_coefficient'], r['cosine_similarity']),\n",
    "                 fontsize=5, alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('GSS Phi-Coefficient', fontsize=12)\n",
    "ax2.set_ylabel('Vector Cosine Similarity', fontsize=12)\n",
    "ax2.set_title('Top/Bottom 20 Correlation Pairs', fontsize=13)\n",
    "ax2.axhline(0, color='gray', linestyle='--', alpha=0.3)\n",
    "ax2.axvline(0, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPearson correlation between phi-coefficient and cosine similarity: {corr:.4f}\")\n",
    "print(f\"Spearman correlation: {comp_df['phi_coefficient'].corr(comp_df['cosine_similarity'], method='spearman'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Comparison\n",
    "\n",
    "Does the demographic PCA structure change across layers? We compare layers 5, 9, 13, 17, 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_layers = [5, 9, 13, 17, 20]\n",
    "layer_results = {}\n",
    "\n",
    "for layer in comparison_layers:\n",
    "    vecs = torch.load(\n",
    "        os.path.join(VECTOR_DIR, f\"gss_demographic_vectors_layer{layer}.pt\"),\n",
    "        map_location=\"cpu\",\n",
    "        weights_only=True,\n",
    "    )\n",
    "\n",
    "    layer_labels = sorted(vecs.keys())\n",
    "    layer_X = np.array([\n",
    "        (vecs[lab]['vector'] * vecs[lab]['magnitude']).numpy()\n",
    "        for lab in layer_labels\n",
    "    ])\n",
    "\n",
    "    layer_pca = PCA(n_components=min(20, len(layer_labels)))\n",
    "    layer_X_pca = layer_pca.fit_transform(layer_X)\n",
    "\n",
    "    layer_results[layer] = {\n",
    "        'labels': layer_labels,\n",
    "        'X': layer_X,\n",
    "        'X_pca': layer_X_pca,\n",
    "        'pca': layer_pca,\n",
    "        'explained_variance': layer_pca.explained_variance_ratio_,\n",
    "    }\n",
    "\n",
    "    print(f\"Layer {layer:2d}: PC1={layer_pca.explained_variance_ratio_[0]:.3f}, \"\n",
    "          f\"PC2={layer_pca.explained_variance_ratio_[1]:.3f}, \"\n",
    "          f\"PC3={layer_pca.explained_variance_ratio_[2]:.3f}, \"\n",
    "          f\"Top-3 cumulative={sum(layer_pca.explained_variance_ratio_[:3]):.3f}, \"\n",
    "          f\"n_vectors={len(layer_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: explained variance comparison across layers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# PC1 explained variance by layer\n",
    "ax = axes[0]\n",
    "for layer in comparison_layers:\n",
    "    ev = layer_results[layer]['explained_variance'][:10]\n",
    "    ax.plot(range(1, 11), ev, 'o-', label=f'Layer {layer}', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Principal Component', fontsize=12)\n",
    "ax.set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "ax.set_title('Explained Variance by Layer', fontsize=13)\n",
    "ax.legend()\n",
    "ax.set_xticks(range(1, 11))\n",
    "\n",
    "# Cumulative comparison\n",
    "ax = axes[1]\n",
    "for layer in comparison_layers:\n",
    "    ev = layer_results[layer]['explained_variance'][:10]\n",
    "    ax.plot(range(1, 11), np.cumsum(ev), 'o-', label=f'Layer {layer}', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Number of Components', fontsize=12)\n",
    "ax.set_ylabel('Cumulative Explained Variance', fontsize=12)\n",
    "ax.set_title('Cumulative Variance by Layer', fontsize=13)\n",
    "ax.legend()\n",
    "ax.set_xticks(range(1, 11))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PC1 poles across layers: are the same demographics at the extremes?\n",
    "print(\"PC1 Poles Across Layers\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for layer in comparison_layers:\n",
    "    r = layer_results[layer]\n",
    "    projections = r['X_pca'][:, 0]\n",
    "    sorted_idx = np.argsort(projections)\n",
    "\n",
    "    top5 = [r['labels'][i].split('_', 1)[1][:30] for i in sorted_idx[-5:][::-1]]\n",
    "    bot5 = [r['labels'][i].split('_', 1)[1][:30] for i in sorted_idx[:5]]\n",
    "\n",
    "    print(f\"\\nLayer {layer} (PC1 = {r['explained_variance'][0]:.1%}):\")\n",
    "    print(f\"  + pole: {', '.join(top5)}\")\n",
    "    print(f\"  - pole: {', '.join(bot5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC1 vs PC2 scatter across layers\n",
    "fig, axes = plt.subplots(1, len(comparison_layers), figsize=(6 * len(comparison_layers), 7))\n",
    "\n",
    "for ax, layer in zip(axes, comparison_layers):\n",
    "    r = layer_results[layer]\n",
    "    layer_cats = [lab.split('_')[0] for lab in r['labels']]\n",
    "\n",
    "    for cat in unique_cats:\n",
    "        mask = [c == cat for c in layer_cats]\n",
    "        if any(mask):\n",
    "            indices = [i for i, m in enumerate(mask) if m]\n",
    "            ax.scatter(\n",
    "                r['X_pca'][indices, 0], r['X_pca'][indices, 1],\n",
    "                label=cat, color=cat_to_color[cat], s=40, alpha=0.7,\n",
    "                edgecolors='white', linewidth=0.3,\n",
    "            )\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=0.2)\n",
    "    ax.axvline(0, color='black', linestyle='--', alpha=0.2)\n",
    "    ax.set_title(f'Layer {layer}', fontsize=13)\n",
    "    ax.set_xlabel(f\"PC1 ({r['explained_variance'][0]:.1%})\")\n",
    "    ax.set_ylabel(f\"PC2 ({r['explained_variance'][1]:.1%})\")\n",
    "\n",
    "axes[-1].legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=6, ncol=2)\n",
    "plt.suptitle('PC1 vs PC2 Across Layers', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter of PC1/PC2/PC3 using matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for cat in unique_cats:\n",
    "    mask = df_pca['category'] == cat\n",
    "    ax.scatter(\n",
    "        df_pca.loc[mask, 'PC1'],\n",
    "        df_pca.loc[mask, 'PC2'],\n",
    "        df_pca.loc[mask, 'PC3'],\n",
    "        label=cat, color=cat_to_color[cat], s=50, alpha=0.7,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontsize=10)\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontsize=10)\n",
    "ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%})', fontsize=10)\n",
    "ax.set_title(f'3D Demographic Space (Layer {REF_LAYER})', fontsize=14)\n",
    "ax.legend(bbox_to_anchor=(1.15, 1), loc='upper left', fontsize=6, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D with plotly (if available)\n",
    "try:\n",
    "    import plotly.express as px\n",
    "\n",
    "    fig = px.scatter_3d(\n",
    "        df_pca, x='PC1', y='PC2', z='PC3',\n",
    "        color='category', hover_name='label',\n",
    "        title=f'Interactive 3D Demographic Space (Layer {REF_LAYER})',\n",
    "        labels={\n",
    "            'PC1': f\"PC1 ({pca.explained_variance_ratio_[0]:.1%})\",\n",
    "            'PC2': f\"PC2 ({pca.explained_variance_ratio_[1]:.1%})\",\n",
    "            'PC3': f\"PC3 ({pca.explained_variance_ratio_[2]:.1%})\",\n",
    "        },\n",
    "        width=900, height=700,\n",
    "    )\n",
    "    fig.show()\n",
    "except ImportError:\n",
    "    print(\"plotly not available — install with: pip install plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Interpretation\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**PC1 — Dominant Axis of Demographic Variation:**\n",
    "- Hypothesized to be the **Liberal-Conservative** axis\n",
    "- Check: Does one pole have Republican/Conservative/Gun owner/Religious, and the other have Democrat/Liberal/Non-religious?\n",
    "- This mirrors the \"Assistant Axis\" (Lu et al., 2026), where PC1 captured the dominant personality variation\n",
    "\n",
    "**PC2 — Second Axis:**\n",
    "- Hypothesized to capture **socioeconomic/education** or **age/generation** variation\n",
    "- Check: Do education levels, income groups, or age groups separate along this axis?\n",
    "\n",
    "**PC3 — Third Axis:**\n",
    "- May capture **urban/rural** or **occupation specificity** variation\n",
    "\n",
    "### GSS Validation\n",
    "- Positive Pearson/Spearman correlation between GSS phi-coefficients and vector cosine similarity would confirm that the model's internal demographic geometry reflects real-world statistical associations\n",
    "\n",
    "### Multi-Layer Structure\n",
    "- The PC structure should emerge most clearly in middle-to-late layers (9-17), where the model adds the most demographic-specific information\n",
    "- Early layers (5) may show less structured variation\n",
    "\n",
    "### Next Steps\n",
    "- **Phase 6**: Use LLM judge filtering to clean vector estimates\n",
    "- **Phase 7**: Track demographic drift in multi-turn conversations on politically charged topics\n",
    "- **Phase 8**: Apply activation capping along the dominant demographic axes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}